{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basketball_reference_web_scraper import client\n",
    "from basketball_reference_web_scraper.data import Team\n",
    "from basketball_reference_web_scraper.data import OutputType\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from pulp import *\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import os.path\n",
    "from os import path\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "from draft_kings.data import Sport\n",
    "from draft_kings.client import contests\n",
    "from draft_kings.client import available_players\n",
    "from draft_kings.client import draft_group_details\n",
    "from draft_kings.client import draftables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_bbref_data():\n",
    "    for m, y in [(11, 2019), (12, 2019), (1, 2020), (2, 2020), (3, 2020)]:\n",
    "        if m == 2:\n",
    "            for d in range(1, 30):\n",
    "                file_name = \"./AllCSVs/{0}_{1}_{2}_box_scores.csv\".format(m, d, y)\n",
    "                client.player_box_scores(day=d, month=m, year=y, output_type=OutputType.CSV, output_file_path=file_name)\n",
    "        elif m == 11:\n",
    "            for d in range(1, 31):\n",
    "                file_name = \"./AllCSVs/{0}_{1}_{2}_box_scores.csv\".format(m, d, y)\n",
    "                client.player_box_scores(day=d, month=m, year=y, output_type=OutputType.CSV, output_file_path=file_name)\n",
    "        else:\n",
    "            for d in range(1, 32):\n",
    "                file_name = \"./AllCSVs/{0}_{1}_{2}_box_scores.csv\".format(m, d, y)\n",
    "                client.player_box_scores(day=d, month=m, year=y, output_type=OutputType.CSV, output_file_path=file_name)\n",
    "scrape_bbref_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bbref_data():\n",
    "    all_tables = []\n",
    "    for m, y in [(11, 2019), (12, 2019), (1, 2020), (2, 2020), (3, 2020)]:\n",
    "        if m == 2:\n",
    "            for d in range(1, 30):\n",
    "                file_name = \"./AllCSVs/{0}_{1}_{2}_box_scores.csv\".format(m, d, y)\n",
    "                table  = pd.read_csv(file_name)\n",
    "                date = datetime(y, m, d)\n",
    "                dates = [date] * len(table)\n",
    "                table[\"Date\"] = dates\n",
    "                all_tables.append(table)\n",
    "\n",
    "        elif m == 11:\n",
    "            for d in range(1, 31):\n",
    "                file_name = \"./AllCSVs/{0}_{1}_{2}_box_scores.csv\".format(m, d, y)\n",
    "                table  = pd.read_csv(file_name)\n",
    "                date = datetime(y, m, d)\n",
    "                dates = [date] * len(table)\n",
    "                table[\"Date\"] = dates\n",
    "                all_tables.append(table)\n",
    "        \n",
    "        else:\n",
    "            for d in range(1, 32):\n",
    "                file_name = \"./AllCSVs/{0}_{1}_{2}_box_scores.csv\".format(m, d, y)\n",
    "                table  = pd.read_csv(file_name)\n",
    "                date = datetime(y, m, d)\n",
    "                dates = [date] * len(table)\n",
    "                table[\"Date\"] = dates\n",
    "                all_tables.append(table)\n",
    "    return all_tables\n",
    "all_tables = load_bbref_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bbref_data():\n",
    "    full_df = all_tables[0]\n",
    "    for i in range(1, len(all_tables)):\n",
    "        current_table = all_tables[i]\n",
    "        full_df = full_df.append(current_table)\n",
    "    full_df.to_csv(\"./OutputCSVs/all_games.csv\")\n",
    "\n",
    "write_bbref_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./OutputCSVs/updated_team_stats.csv\")\n",
    "df[\"team\"] = df[\"team\"].str.upper()\n",
    "all_games = pd.read_csv(\"./OutputCSVs/all_games.csv\")\n",
    "\n",
    "team_def = []\n",
    "team_pace = []\n",
    "team_tov = []\n",
    "opp_def = []\n",
    "opp_pace = []\n",
    "opp_tov = []\n",
    "all_games_teams = all_games[[\"team\", \"opponent\"]]\n",
    "\n",
    "for i in range(len(all_games_teams)):\n",
    "    game = all_games_teams.loc[i]\n",
    "    team = game[\"team\"]\n",
    "    opponent = game[\"opponent\"]\n",
    "    team_def.append(df[df[\"team\"] == team][\"drtg\"].iloc[0])\n",
    "    team_pace.append(df[df[\"team\"] == team][\"pace\"].iloc[0])\n",
    "    team_tov.append(df[df[\"team\"] == team][\"tov%\"].iloc[0])\n",
    "    opp_def.append(df[df[\"team\"] == opponent][\"drtg\"].iloc[0])\n",
    "    opp_pace.append(df[df[\"team\"] == opponent][\"pace\"].iloc[0])\n",
    "    opp_tov.append(df[df[\"team\"] == opponent][\"tov%\"].iloc[0])\n",
    "    \n",
    "all_games[\"Team Defensive Rating\"] = team_def\n",
    "all_games[\"Team Pace\"] = team_pace\n",
    "all_games[\"Team Turnover %\"] = team_tov\n",
    "all_games[\"Opponent Defensive Rating\"] = opp_def\n",
    "all_games[\"Opponent Pace\"] = opp_pace\n",
    "all_games[\"Opponent Turnover %\"] = opp_tov\n",
    "\n",
    "all_games.to_csv(\"./OutputCSVs/all_games_new.csv\")\n",
    "df = pd.read_csv(\"./OutputCSVs/all_games_new.csv\")\n",
    "attempted_2s = df[\"attempted_field_goals\"] - df[\"attempted_three_point_field_goals\"]\n",
    "made_2s = df[\"made_field_goals\"] - df[\"made_three_point_field_goals\"]\n",
    "rebounds = df[\"offensive_rebounds\"] + df[\"defensive_rebounds\"]\n",
    "at_home = df[\"location\"] == \"HOME\"\n",
    "df[\"attempted_two_point_field_goals\"] = attempted_2s\n",
    "df[\"made_two_point_field_goals\"] = made_2s\n",
    "df[\"total_rebounds\"] = rebounds\n",
    "df[\"at_home\"] = at_home\n",
    "df.to_csv(\"./OutputCSVs/all_games_updated.csv\")\n",
    "all_games_actual = pd.read_csv(\"./OutputCSVs/all_games_updated.csv\")\n",
    "all_games_actual =  all_games_actual.iloc[:, 3:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(player, date, number_rows):\n",
    "    converted_datetime = datetime.strptime(date, '%Y-%m-%d')\n",
    "    player_rows = all_games_actual.loc[all_games_actual['name'] == player]\n",
    "    #print(player_rows)\n",
    "    selected_rows = []\n",
    "    if (len(player_rows)) < number_rows:\n",
    "        for i in range(len(player_rows)):\n",
    "            selected_rows.append(player_rows.iloc[i])\n",
    "        return pd.DataFrame(selected_rows)\n",
    "    index = 0\n",
    "    for i in range(len(player_rows)):\n",
    "        curr_date = player_rows.iloc[i]['Date']\n",
    "        if datetime.strptime(curr_date, '%Y-%m-%d') >= converted_datetime:\n",
    "            index = i - 1\n",
    "            break\n",
    "    if index != 0:\n",
    "        if index + 1 - number_rows < 0:\n",
    "            for i in range(index + 1):\n",
    "                selected_rows.append(player_rows.iloc[i])\n",
    "        else:\n",
    "            for i in range(index + 1 - number_rows, index + 1):\n",
    "                selected_rows.append(player_rows.iloc[i])\n",
    "#     elif converted_datetime >= players_rows[len(player_rows) - 1]:\n",
    "    else:\n",
    "        for i in range(len(player_rows) - number_rows, len(player_rows)):\n",
    "            selected_rows.append(player_rows.iloc[i])\n",
    "    return pd.DataFrame(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(row_data):\n",
    "    if 'made_three_point_field_goals_y' in row_data.columns:\n",
    "        three_pt_fgs = row_data['made_three_point_field_goals_y']\n",
    "        two_pt_fgs = row_data['made_two_point_field_goals_y']\n",
    "        made_fts = row_data['made_free_throws_y']\n",
    "        total_rebounds = row_data['rebounds_y']\n",
    "        assists = row_data['assists_y']\n",
    "        blocks = row_data['blocks_y']\n",
    "        steals = row_data['steals_y']\n",
    "        turnovers = row_data['turnovers_y']\n",
    "    else:\n",
    "        three_pt_fgs = row_data['made_three_point_field_goals']\n",
    "        two_pt_fgs = row_data['made_two_point_field_goals']\n",
    "        made_fts = row_data['made_free_throws']\n",
    "        total_rebounds = row_data['rebounds']\n",
    "        assists = row_data['assists']\n",
    "        blocks = row_data['blocks']\n",
    "        steals = row_data['steals']\n",
    "        turnovers = row_data['turnovers']\n",
    "    FD_points = three_pt_fgs * 3 + two_pt_fgs * 2 + made_fts + total_rebounds * 1.2 + assists * 1.5 + blocks * 3 + steals * 3 - turnovers\n",
    "    FD_dollars = FD_points * 200\n",
    "    return (FD_points, FD_dollars)\n",
    "\n",
    "def double_double(threes, twos, fts, rebounds, assists):\n",
    "    points = float(threes) * 3 + float(twos) * 2 + float(fts)\n",
    "    rebounds = rebounds.tolist()[0]\n",
    "    assists = assists.tolist()[0]\n",
    "    return (points >= 10 and rebounds >= 10) or (points >= 10 and assists >= 10) or (rebounds >= 10 and assists >= 10)\n",
    "\n",
    "def triple_double(threes, twos, fts, rebounds, assists):\n",
    "    points = float(threes) * 3 + float(twos) * 2 + float(fts)\n",
    "    rebounds = rebounds.tolist()[0]\n",
    "    assists = assists.tolist()[0]\n",
    "    return points >= 10 and rebounds >= 10 and assists >= 10\n",
    "\n",
    "def get_draftkings_points(row_data):\n",
    "    if 'made_three_point_field_goals_y' in row_data.columns:\n",
    "        three_pt_fgs = float(row_data['made_three_point_field_goals_y'])\n",
    "        two_pt_fgs = float(row_data['made_two_point_field_goals_y'])\n",
    "        made_fts = float(row_data['made_free_throws_y'])\n",
    "        total_rebounds = float(row_data['rebounds_y'])\n",
    "        assists = float(row_data['assists_y'])\n",
    "        blocks = row_data['blocks_y']\n",
    "        steals = row_data['steals_y']\n",
    "        turnovers = row_data['turnovers_y']\n",
    "    else:\n",
    "        three_pt_fgs = float(row_data['made_three_point_field_goals'])\n",
    "        two_pt_fgs = float(row_data['made_two_point_field_goals'])\n",
    "        made_fts = float(row_data['made_free_throws'])\n",
    "        total_rebounds = row_data['rebounds']\n",
    "        assists = row_data['assists']\n",
    "        blocks = row_data['blocks']\n",
    "        steals = row_data['steals']\n",
    "        turnovers = row_data['turnovers']\n",
    "    DK_points = three_pt_fgs * 3.5 + two_pt_fgs * 2 + made_fts + total_rebounds * 1.25 + assists * 1.5 + blocks * 2 + steals * 2 - .5 * turnovers + 1.5 * double_double(three_pt_fgs, two_pt_fgs, made_fts, rebounds, assists) + 3 * triple_double(three_pt_fgs, two_pt_fgs, made_fts, rebounds, assists)\n",
    "    DK_dollars = DK_points * 187.5\n",
    "    return (DK_points, DK_dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_function(statistic, weight):\n",
    "    s = 0\n",
    "    if type(statistic) == np.ndarray:\n",
    "        for i in range(len(statistic)):\n",
    "            s += statistic[len(statistic) - i - 1] * (weight ** i)\n",
    "    else:\n",
    "        for i in range(len(statistic)):\n",
    "            s += statistic.iloc[len(statistic) - i - 1,] * (weight ** i)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_weighted_average(rows, statistic, weight):\n",
    "    if rows.empty:\n",
    "        return 0\n",
    "    stat = rows[statistic]\n",
    "    this_num = 1 / weight_function(np.ones(len(stat)), weight)\n",
    "    return this_num * weight_function(stat, weight)\n",
    "player_box_scores = pd.read_csv('./OutputCSVs/all_games_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statline_predictor(player_box_scores, input_statistics, sample_size = 5, weight = .8):\n",
    "    player_box_scores = player_box_scores[~player_box_scores.index.duplicated()]\n",
    "    player_box_scores.reindex(range(len(player_box_scores)), axis = \"index\")\n",
    "    predicted_statlines = pd.DataFrame(index = player_box_scores.index, columns = input_statistics).fillna(0).T\n",
    "    index_len = len(player_box_scores.index)\n",
    "    for box_index in player_box_scores.index:\n",
    "        box_score = player_box_scores.loc[box_index]\n",
    "        player_name = box_score[\"name\"]\n",
    "        game_date = str(box_score[\"Date\"])[:10]\n",
    "        last_n_rows = get_stats(player_name, game_date, sample_size)\n",
    "        weighted_stats = [player_name, box_score[\"team\"], game_date, box_score[\"location\"], box_score[\"opponent\"]]\n",
    "        for stat in input_statistics[5:]:\n",
    "            weighted_stats.append(round(time_weighted_average(last_n_rows, stat, weight), 2))\n",
    "        predicted_statlines[box_index] = weighted_stats\n",
    "    return predicted_statlines.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_predictor(weighted_stats):\n",
    "    if \"seconds_played_y\" in weighted_stats.index:\n",
    "        return np.mean(weighted_stats[\"seconds_played_y\"])/60\n",
    "    else:\n",
    "        return np.mean(weighted_stats[\"seconds_played\"])/60\n",
    "def recent_average(weighted_stats):\n",
    "    if len(weighted_stats.index) == 0:\n",
    "        return 0\n",
    "    if \"made_three_point_field_goals_y\" in weighted_stats.index:\n",
    "        return 3*np.mean(weighted_stats[\"made_three_point_field_goals_y\"]) + 2*np.mean(weighted_stats[\"made_two_point_field_goals_y\"]) + np.mean(weighted_stats[\"made_free_throws_y\"]) + 1.2*(np.mean(weighted_stats[\"offensive_rebounds_y\"]) + np.mean(weighted_stats[\"defensive_rebounds_y\"])) + 1.5*np.mean(weighted_stats[\"assists_y\"]) + 3*np.mean(weighted_stats[\"blocks_y\"]) + 3*np.mean(weighted_stats[\"steals_y\"]) - np.mean(weighted_stats[\"turnovers_y\"])\n",
    "    else:\n",
    "        return 3*np.mean(weighted_stats[\"made_three_point_field_goals\"]) + 2*np.mean(weighted_stats[\"made_two_point_field_goals\"]) + np.mean(weighted_stats[\"made_free_throws\"]) + 1.2*(np.mean(weighted_stats[\"offensive_rebounds\"]) + np.mean(weighted_stats[\"defensive_rebounds\"])) + 1.5*np.mean(weighted_stats[\"assists\"]) + 3*np.mean(weighted_stats[\"blocks\"]) + 3*np.mean(weighted_stats[\"steals\"]) - np.mean(weighted_stats[\"turnovers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_abbrv = {'ATLANTA HAWKS':'Atlanta', 'BOSTON CELTICS':'Boston', 'BROOKLYN NETS':'Brooklyn', 'CHARLOTTE HORNETS':'Charlotte', 'CHICAGO BULLS':'Chicago', 'CLEVELAND CAVALIERS':'Cleveland', 'DALLAS MAVERICKS':'Dallas',\n",
    "            'DENVER NUGGETS':'Denver', 'DETROIT PISTONS':'Detroit', 'GOLDEN STATE WARRIORS':'Golden State', 'HOUSTON ROCKETS':'Houston', 'INDIANA PACERS':'Indiana', 'LOS ANGELES CLIPPERS':'LA Clippers', 'LOS ANGELES LAKERS':'LA Lakers',\n",
    "            'MEMPHIS GRIZZLIES':'Memphis', 'MIAMI HEAT':'Miami', 'MILWAUKEE BUCKS':'Milwaukee', 'MINNESOTA TIMBERWOLVES':'Minnesota', 'NEW ORLEANS PELICANS':'New Orleans', 'NEW YORK KNICKS':'New York', 'OKLAHOMA CITY THUNDER':'Oklahoma City', 'ORLANDO MAGIC':'Orlando',\n",
    "            'PHILADELPHIA 76ERS':'Philadelphia', 'PHOENIX SUNS':'Phoenix', 'PORTLAND TRAIL BLAZERS':'Portland', 'SACRAMENTO KINGS':'Sacramento', 'SAN ANTONIO SPURS':'San Antonio', 'TORONTO RAPTORS':'Toronto', 'UTAH JAZZ':'Utah', 'WASHINGTON WIZARDS':'Washington'}\n",
    "positions = pd.read_csv('./OutputCSVs/all_player_positions.csv')\n",
    "dbp = pd.read_csv('./OutputCSVs/team_def_vs_position.csv')\n",
    "main_df = pd.read_csv('./AllCSVs/predictions_for_07_31_2020_unplayed.csv')\n",
    "\n",
    "def process_dual_positions(position1, position2, team, opponent):\n",
    "    first_team_subrank =  dbp.loc[dbp['Team']==team, 'vs {0}'.format(position1)].iloc[0]\n",
    "    second_team_subrank =  dbp.loc[dbp['Team']==team, 'vs {0}'.format(position2)].iloc[0]\n",
    "    first_opp_subrank =  dbp.loc[dbp['Team']==opponent, 'vs {0}'.format(position1)].iloc[0]\n",
    "    second_opp_subrank =  dbp.loc[dbp['Team']==opponent, 'vs {0}'.format(position2)].iloc[0]\n",
    "    return first_team_subrank, second_team_subrank, first_opp_subrank, second_opp_subrank\n",
    "    \n",
    "def add_team_defense(main_df):\n",
    "    team_def_vs_pos = []\n",
    "    opp_def_vs_pos = []\n",
    "\n",
    "    player_positions = pd.Series(positions['position'].values,index=positions['player name']).to_dict()\n",
    "\n",
    "    for i in range(len(main_df)):\n",
    "        name = main_df['name'][i]\n",
    "        position = player_positions.get(name)\n",
    "        team = all_abbrv.get(main_df['team'][i])\n",
    "        opponent = all_abbrv.get(main_df['opponent'][i])\n",
    "        if position is None:\n",
    "            team_def_vs_pos.append('')\n",
    "            opp_def_vs_pos.append('')\n",
    "        else:\n",
    "            if position in ['PG','SG','SF','PF','C']:\n",
    "                team_def_vs_pos.append(dbp.loc[dbp['Team']==team, 'vs {0}'.format(position)].iloc[0])\n",
    "                opp_def_vs_pos.append(dbp.loc[dbp['Team']==opponent, 'vs {0}'.format(position)].iloc[0])\n",
    "            elif position == 'G':\n",
    "                pdp = process_dual_positions('PG', 'SG', team, opponent)\n",
    "                team_def_vs_pos.append((pdp[0] + pdp[1])/2)\n",
    "                opp_def_vs_pos.append((pdp[2] + pdp[3])/2)\n",
    "            elif position == 'F':\n",
    "                pdp = process_dual_positions('SF', 'PF', team, opponent)\n",
    "                team_def_vs_pos.append((pdp[0] + pdp[1])/2)\n",
    "                opp_def_vs_pos.append((pdp[2] + pdp[3])/2)\n",
    "            elif position in ['G-F','F-G']:\n",
    "                pdp = process_dual_positions('SG', 'SF', team, opponent)\n",
    "                team_def_vs_pos.append((pdp[0] + pdp[1])/2)\n",
    "                opp_def_vs_pos.append((pdp[2] + pdp[3])/2)\n",
    "            elif position in ['F-C']:\n",
    "                pdp = process_dual_positions('PF', 'C', team, opponent)\n",
    "                team_def_vs_pos.append((pdp[0] + pdp[1])/2)\n",
    "                opp_def_vs_pos.append((pdp[2] + pdp[3])/2)\n",
    "    #main_df['team def vs pos'] = team_def_vs_pos\n",
    "    main_df['Opponent Defensive Rank vs Position'] = opp_def_vs_pos\n",
    "    return main_df\n",
    "#add_team_defense(pd.read_csv('./AllCSVs/predictions_for_07_31_2020_unplayed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_statistics = [\"name\", \"team\", \"date\", \"location\", \"opponent\", \"made_field_goals\", \"made_two_point_field_goals\", \"attempted_two_point_field_goals\", \"attempted_field_goals\", \"made_three_point_field_goals\", \"attempted_three_point_field_goals\", \"attempted_free_throws\", \"made_free_throws\", \"offensive_rebounds\", \"defensive_rebounds\", \"assists\", \"blocks\", \"turnovers\", \"steals\", \"seconds_played\", \"Opponent Defensive Rating\", \"Opponent Turnover %\", 'Team Defensive Rating', 'Team Pace', 'Team Turnover %', 'Opponent Pace']\n",
    "output_statistics = [\"name\", \"team\", \"date\", \"location\", \"opponent\", \"minutes\", \"made_two_point_field_goals\", \"made_three_point_field_goals\", \"made_free_throws\", \"rebounds\", \"assists\", \"blocks\", \"steals\", \"turnovers\", \"recent_average\", \"10_game_average\", \"3_game_average\", \"10_3_ratio\", \"10_3_difference\", \"hot\", \"cold\", \"fantasy_points\"]\n",
    "\n",
    "def statline_output(player_box_scores, input_statistics):\n",
    "    weighted_lines_7_9 = statline_predictor(player_box_scores, input_statistics, 7, .9)\n",
    "    weighted_lines_8_8 = statline_predictor(player_box_scores, input_statistics, 8, .8)\n",
    "    weighted_lines_8_85 = statline_predictor(player_box_scores, input_statistics, 8, .85)\n",
    "    weighted_lines_8_9 = statline_predictor(player_box_scores, input_statistics, 8, .9)\n",
    "    weighted_lines_to_keep_7_9 = weighted_lines_7_9[weighted_lines_7_9.seconds_played > 1000]\n",
    "    weighted_lines_to_keep_8_8 = weighted_lines_8_8[weighted_lines_8_8.seconds_played > 1000]\n",
    "    weighted_lines_to_keep_8_85 = weighted_lines_8_85[weighted_lines_8_85.seconds_played > 1000]\n",
    "    weighted_lines_to_keep_8_9 = weighted_lines_8_9[weighted_lines_8_9.seconds_played > 1000]\n",
    "    df_to_keep = player_box_scores[weighted_lines_8_9.seconds_played > 1000]\n",
    "    df_to_keep[\"attempted_two_point_field_goals\"] = df_to_keep[\"attempted_field_goals\"] - df_to_keep[\"attempted_three_point_field_goals\"]\n",
    "    df_to_keep[\"made_two_point_field_goals\"] = df_to_keep[\"made_field_goals\"] - df_to_keep[\"made_three_point_field_goals\"]\n",
    "    weighted_lines_to_keep_7_9['name_date'] = weighted_lines_to_keep_7_9[\"name\"] + weighted_lines_to_keep_7_9[\"date\"].astype(str)\n",
    "    weighted_lines_to_keep_8_8['name_date'] = weighted_lines_to_keep_8_8[\"name\"] + weighted_lines_to_keep_8_8[\"date\"].astype(str)\n",
    "    weighted_lines_to_keep_8_85['name_date'] = weighted_lines_to_keep_8_85[\"name\"] + weighted_lines_to_keep_8_85[\"date\"].astype(str)\n",
    "    weighted_lines_to_keep_8_9['name_date'] = weighted_lines_to_keep_8_9[\"name\"] + weighted_lines_to_keep_8_9[\"date\"].astype(str)\n",
    "    df_to_keep['name_date'] = df_to_keep[\"name\"] + df_to_keep[\"Date\"].astype(str)\n",
    "    df_merged_7_9 = weighted_lines_to_keep_7_9.merge(df_to_keep, left_on = 'name_date', right_on = 'name_date')\n",
    "    df_merged_7_9[\"rebounds_y\"] = df_merged_7_9[\"offensive_rebounds_y\"] + df_merged_7_9[\"defensive_rebounds_y\"]\n",
    "    df_merged_7_9[\"location_x\"] = df_merged_7_9[\"location_x\"] == \"HOME\"\n",
    "    df_merged_7_9[\"location_y\"] = df_merged_7_9[\"location_y\"] == \"HOME\"\n",
    "    df_merged_8_8 = weighted_lines_to_keep_8_8.merge(df_to_keep, left_on = 'name_date', right_on = 'name_date')\n",
    "    df_merged_8_8[\"rebounds_y\"] = df_merged_8_8[\"offensive_rebounds_y\"] + df_merged_8_8[\"defensive_rebounds_y\"]\n",
    "    df_merged_8_8[\"location_x\"] = df_merged_8_8[\"location_x\"] == \"HOME\"\n",
    "    df_merged_8_8[\"location_y\"] = df_merged_8_8[\"location_y\"] == \"HOME\"\n",
    "    df_merged_8_85 = weighted_lines_to_keep_8_85.merge(df_to_keep, left_on = 'name_date', right_on = 'name_date')\n",
    "    df_merged_8_85[\"rebounds_y\"] = df_merged_8_85[\"offensive_rebounds_y\"] + df_merged_8_85[\"defensive_rebounds_y\"]\n",
    "    df_merged_8_85[\"location_x\"] = df_merged_8_85[\"location_x\"] == \"HOME\"\n",
    "    df_merged_8_85[\"location_y\"] = df_merged_8_85[\"location_y\"] == \"HOME\"\n",
    "    df_merged_8_9 = weighted_lines_to_keep_8_9.merge(df_to_keep, left_on = 'name_date', right_on = 'name_date')\n",
    "    df_merged_8_9[\"rebounds_y\"] = df_merged_8_9[\"offensive_rebounds_y\"] + df_merged_8_9[\"defensive_rebounds_y\"]\n",
    "    df_merged_8_9[\"location_x\"] = df_merged_8_9[\"location_x\"] == \"HOME\"\n",
    "    df_merged_8_9[\"location_y\"] = df_merged_8_9[\"location_y\"] == \"HOME\"\n",
    "    predictors_7_9 = df_merged_7_9.iloc[:,[3, 7, 6, 9, 10, 12, 11, 13, 14, 15, 18, 16, 17, 22, 23, 24, 20, 25, 21]]\n",
    "    predictors_8_8 = df_merged_8_8.iloc[:,[3, 7, 6, 9, 10, 12, 11, 13, 14, 15, 18, 16, 17, 22, 23, 24, 20, 25, 21]]\n",
    "    predictors_8_85 = df_merged_8_85.iloc[:,[3, 7, 6, 9, 10, 12, 11, 13, 14, 15, 18, 16, 17, 22, 23, 24, 20, 25, 21]]\n",
    "    predictors_8_9 = df_merged_8_9.iloc[:,[3, 7, 6, 9, 10, 12, 11, 13, 14, 15, 18, 16, 17, 22, 23, 24, 20, 25, 21]]\n",
    "    df_merged_7_9[\"fantasy_points\"] = [float(get_points(df_merged_7_9[df_merged_7_9[\"name_date\"] == player_name])[0]) for player_name in df_merged_7_9[\"name_date\"]]\n",
    "    df_merged_8_8[\"fantasy_points\"] = [float(get_points(df_merged_8_8[df_merged_8_8[\"name_date\"] == player_name])[0]) for player_name in df_merged_8_8[\"name_date\"]]\n",
    "    df_merged_8_85[\"fantasy_points\"] = [float(get_points(df_merged_8_85[df_merged_8_85[\"name_date\"] == player_name])[0]) for player_name in df_merged_8_85[\"name_date\"]]\n",
    "    df_merged_8_9[\"fantasy_points\"] = [float(get_points(df_merged_8_9[df_merged_8_9[\"name_date\"] == player_name])[0]) for player_name in df_merged_8_9[\"name_date\"]]\n",
    "    fantasy_points_8_9 = df_merged_8_9.iloc[:,58]\n",
    "    freethrows = df_merged_7_9.iloc[:,38]\n",
    "    twopoints = df_merged_8_8.iloc[:,56]\n",
    "    threepoints = df_merged_8_85.iloc[:,36]\n",
    "    blocks = df_merged_8_85.iloc[:,44]\n",
    "    assists = df_merged_8_9.iloc[:,42]\n",
    "    rebounds = df_merged_8_9.iloc[:,57]\n",
    "    turnovers = df_merged_8_9.iloc[:,45]\n",
    "    seconds = df_merged_8_9.iloc[:,33]\n",
    "    steals = df_merged_8_9.iloc[:,43]\n",
    "    fantasy_model_8_9 = RidgeCV().fit(predictors_8_9, fantasy_points_8_9)\n",
    "    freethrow_model = RidgeCV().fit(predictors_7_9, freethrows)\n",
    "    twopoint_model = RidgeCV().fit(predictors_8_8, twopoints)\n",
    "    threepoint_model = RidgeCV().fit(predictors_8_85, threepoints)\n",
    "    block_model = RidgeCV().fit(predictors_8_85, blocks)\n",
    "    assist_model = RidgeCV().fit(predictors_8_9, assists)\n",
    "    rebound_model = RidgeCV().fit(predictors_8_9, rebounds)\n",
    "    turnover_model = RidgeCV().fit(predictors_8_9, turnovers)\n",
    "    second_model = RidgeCV().fit(predictors_8_9, seconds)\n",
    "    steal_model = RidgeCV().fit(predictors_8_9, steals)\n",
    "\n",
    "    \n",
    "    output_statlines = pd.DataFrame(index = weighted_lines_8_9.index, columns = output_statistics).fillna(0)\n",
    "    output_statlines[\"name\"] = weighted_lines_8_9[\"name\"]\n",
    "    output_statlines[\"team\"] = weighted_lines_8_9[\"team\"]\n",
    "    output_statlines[\"date\"] = weighted_lines_8_9[\"date\"]\n",
    "    output_statlines[\"location\"] = weighted_lines_8_9[\"location\"]\n",
    "    output_statlines[\"opponent\"] = weighted_lines_8_9[\"opponent\"]\n",
    "    weighted_lines_7_9[\"location\"] = weighted_lines_7_9[\"location\"] == \"HOME\"\n",
    "    weighted_lines_8_8[\"location\"] = weighted_lines_8_8[\"location\"] == \"HOME\"\n",
    "    weighted_lines_8_85[\"location\"] = weighted_lines_8_85[\"location\"] == \"HOME\"\n",
    "    weighted_lines_8_9[\"location\"] = weighted_lines_8_9[\"location\"] == \"HOME\"\n",
    "    weighted_lines_7_9 = weighted_lines_7_9.iloc[:, [3, 7, 6, 9, 10, 12, 11, 13, 14, 15, 18, 16, 17, 22, 23, 24, 20, 25, 21]]\n",
    "    weighted_lines_8_8 = weighted_lines_8_8.iloc[:, [3, 7, 6, 9, 10, 12, 11, 13, 14, 15, 18, 16, 17, 22, 23, 24, 20, 25, 21]]\n",
    "    weighted_lines_8_85 = weighted_lines_8_85.iloc[:, [3, 7, 6, 9, 10, 12, 11, 13, 14, 15, 18, 16, 17, 22, 23, 24, 20, 25, 21]]\n",
    "    weighted_lines_8_9 = weighted_lines_8_9.iloc[:, [3, 7, 6, 9, 10, 12, 11, 13, 14, 15, 18, 16, 17, 22, 23, 24, 20, 25, 21]]\n",
    "\n",
    "    output_statlines[\"minutes\"] = second_model.predict(weighted_lines_8_9) / 60\n",
    "    output_statlines[\"made_two_point_field_goals\"] = twopoint_model.predict(weighted_lines_8_8)\n",
    "    output_statlines[\"made_three_point_field_goals\"] = threepoint_model.predict(weighted_lines_8_85) \n",
    "    output_statlines[\"made_free_throws\"] = freethrow_model.predict(weighted_lines_7_9)\n",
    "    output_statlines[\"rebounds\"] = rebound_model.predict(weighted_lines_8_9)\n",
    "    output_statlines[\"assists\"] = assist_model.predict(weighted_lines_8_9)\n",
    "    output_statlines[\"blocks\"] = block_model.predict(weighted_lines_8_85)\n",
    "    output_statlines[\"steals\"] = steal_model.predict(weighted_lines_8_9) \n",
    "    output_statlines[\"turnovers\"] = turnover_model.predict(weighted_lines_8_9)\n",
    "    output_statlines[\"fantasy_points_8_9\"] = fantasy_model_8_9.predict(weighted_lines_8_9)\n",
    "    for box_index in output_statlines.index:\n",
    "        if output_statlines.loc[box_index, \"fantasy_points_8_9\"] < -100:\n",
    "            output_statlines.loc[box_index, \"minutes\"] = 4\n",
    "        pred_minutes = max(0, output_statlines.loc[box_index, \"minutes\"])\n",
    "        if pred_minutes <= 19:\n",
    "            output_statlines.loc[box_index, \"made_two_point_field_goals\"] = output_statlines.loc[box_index, \"made_two_point_field_goals\"] * pred_minutes/19\n",
    "            output_statlines.loc[box_index, \"made_three_point_field_goals\"] = output_statlines.loc[box_index, \"made_three_point_field_goals\"] * pred_minutes/19\n",
    "            output_statlines.loc[box_index, \"made_free_throws\"] = output_statlines.loc[box_index, \"made_free_throws\"] * pred_minutes/19\n",
    "            output_statlines.loc[box_index, \"rebounds\"] = output_statlines.loc[box_index, \"rebounds\"] * pred_minutes/19\n",
    "            output_statlines.loc[box_index, \"assists\"] = output_statlines.loc[box_index, \"assists\"] * pred_minutes/19\n",
    "            output_statlines.loc[box_index, \"blocks\"] = output_statlines.loc[box_index, \"blocks\"] * pred_minutes/19\n",
    "            output_statlines.loc[box_index, \"steals\"] = output_statlines.loc[box_index, \"steals\"] * pred_minutes/19\n",
    "            output_statlines.loc[box_index, \"turnovers\"] = output_statlines.loc[box_index, \"turnovers\"] * pred_minutes/19\n",
    "        output_statlines.loc[box_index, \"minutes\"] = round(pred_minutes, 2)\n",
    "        output_statlines.loc[box_index, \"made_two_point_field_goals\"] = round(max(0, output_statlines.loc[box_index, \"made_two_point_field_goals\"]), 2)\n",
    "        output_statlines.loc[box_index, \"made_three_point_field_goals\"] = round(max(0, output_statlines.loc[box_index, \"made_three_point_field_goals\"]), 2)\n",
    "        output_statlines.loc[box_index, \"made_free_throws\"] = round(max(0, output_statlines.loc[box_index, \"made_free_throws\"]), 2)\n",
    "        output_statlines.loc[box_index, \"rebounds\"] = round(max(0, output_statlines.loc[box_index, \"rebounds\"]), 2)\n",
    "        output_statlines.loc[box_index, \"assists\"] = round(max(0, output_statlines.loc[box_index, \"assists\"]), 2)\n",
    "        output_statlines.loc[box_index, \"blocks\"] = round(max(0, output_statlines.loc[box_index, \"blocks\"]), 2)\n",
    "        output_statlines.loc[box_index, \"steals\"] = round(max(0, output_statlines.loc[box_index, \"steals\"]), 2)\n",
    "        output_statlines.loc[box_index, \"turnovers\"] = round(max(0, output_statlines.loc[box_index, \"turnovers\"]), 2)\n",
    "        output_statlines.loc[box_index, \"recent_average\"] = round(np.mean([recent_average(weighted_lines_8_85.loc[box_index]), recent_average(weighted_lines_8_9.loc[box_index]), recent_average(weighted_lines_8_8.loc[box_index]), recent_average(weighted_lines_7_9.loc[box_index])]), 2)\n",
    "        last_10_games = get_stats(output_statlines.loc[box_index, \"name\"], output_statlines.loc[box_index, \"date\"], 10)\n",
    "        last_3_games = get_stats(output_statlines.loc[box_index, \"name\"], output_statlines.loc[box_index, \"date\"], 3)\n",
    "        output_statlines.loc[box_index, \"10_game_average\"] = round(recent_average(last_10_games), 2)\n",
    "        output_statlines.loc[box_index, \"3_game_average\"] = round(recent_average(last_3_games), 2)\n",
    "        output_statlines.loc[box_index, \"10_3_ratio\"] = (output_statlines.loc[box_index, \"10_game_average\"] + 1)/(output_statlines.loc[box_index, \"3_game_average\"] + 1)\n",
    "        output_statlines.loc[box_index, \"10_3_difference\"] = output_statlines.loc[box_index, \"10_game_average\"] - output_statlines.loc[box_index, \"3_game_average\"]\n",
    "        output_statlines.loc[box_index, \"hot\"] = np.log(((-7 * min(0, output_statlines.loc[box_index, \"10_3_ratio\"] - .83)) * (-1 * min(0, output_statlines.loc[box_index, \"10_3_difference\"] + 6))) + 1)\n",
    "        output_statlines.loc[box_index, \"cold\"] = np.log(((7 * max(0, output_statlines.loc[box_index, \"10_3_ratio\"] - 1.22)) * (max(0, output_statlines.loc[box_index, \"10_3_difference\"] - 6.5))) + 1)\n",
    "    \n",
    "    output_statlines = add_team_defense(output_statlines)\n",
    "    return output_statlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_optimal_lineup(players, positions, values, costs, budget):\n",
    "    num_variables = len(players)\n",
    "    \n",
    "    lp = LpProblem(\"My LP Problem\", pulp.LpMaximize)\n",
    "    \n",
    "    d = {}\n",
    "    for i in range(0, num_variables):\n",
    "        d[players[i]] = LpVariable(players[i], cat=\"Binary\")\n",
    "    \n",
    "    objective = sum(np.array(values) * np.array(list(d.values())))\n",
    "    lp += objective\n",
    "    \n",
    "    pg_constraint = 0\n",
    "    sg_constraint = 0\n",
    "    sf_constraint = 0\n",
    "    pf_constraint = 0\n",
    "    c_constraint = 0\n",
    "    for i in range(0, len(positions)):\n",
    "        if positions[i] == \"PG\":\n",
    "            pg_constraint += d[players[i]]\n",
    "        elif positions[i] == \"SG\":\n",
    "            sg_constraint += d[players[i]]\n",
    "        elif positions[i] == \"SF\":\n",
    "            sf_constraint += d[players[i]]\n",
    "        elif positions[i] == \"PF\":\n",
    "            pf_constraint += d[players[i]]\n",
    "        else:\n",
    "            c_constraint += d[players[i]]\n",
    "    lp += pg_constraint == 2\n",
    "    lp += sg_constraint == 2\n",
    "    lp += sf_constraint == 2\n",
    "    lp += pf_constraint == 2\n",
    "    lp += c_constraint == 1\n",
    "    \n",
    "    cost = sum(np.array(costs) * np.array(list(d.values())))\n",
    "    lp += cost <= budget\n",
    "    \n",
    "    lp.solve()\n",
    "    \n",
    "    lineup = [variable.name for variable in lp.variables() if variable.varValue == 1]\n",
    "    return lineup\n",
    "\n",
    "def generate_optimal_lineup_draftkings(players, positions, values, costs, budget):\n",
    "    num_variables = len(players)\n",
    "    \n",
    "    lp = LpProblem(\"My LP Problem\", pulp.LpMaximize)\n",
    "    \n",
    "    d = {}\n",
    "    for i in range(0, num_variables):\n",
    "        d[players[i]] = LpVariable(players[i], cat=\"Binary\")\n",
    "    \n",
    "    objective = sum(np.array(values) * np.array(list(d.values())))\n",
    "    lp += objective\n",
    "    \n",
    "    pg_constraint = 0\n",
    "    sg_constraint = 0\n",
    "    sf_constraint = 0\n",
    "    pf_constraint = 0\n",
    "    c_constraint = 0\n",
    "    g_constraint = 0\n",
    "    f_constraint = 0\n",
    "    player_constraint = 0\n",
    "    for i in range(0, len(positions)):\n",
    "        if \"PG\" in positions[i] or \"SG\" in positions[i]:\n",
    "            if \"PG\" in positions[i]:\n",
    "                pg_constraint += d[players[i]]\n",
    "            if \"SG\" in positions[i]:\n",
    "                sg_constraint += d[players[i]]\n",
    "            g_constraint += d[players[i]]\n",
    "        if \"PF\" in positions[i] or \"SF\" in positions[i]:\n",
    "            if \"PF\" in positions[i]:\n",
    "                pf_constraint += d[players[i]]\n",
    "            if \"SF\" in positions[i]:\n",
    "                sf_constraint += d[players[i]]\n",
    "            f_constraint += d[players[i]]\n",
    "        if \"C\" in positions[i]:\n",
    "            c_constraint += d[players[i]]\n",
    "        player_constraint += d[players[i]]\n",
    "    lp += pg_constraint <= 3\n",
    "    lp += sg_constraint <= 3\n",
    "    lp += sf_constraint <= 3\n",
    "    lp += pf_constraint <= 3\n",
    "    lp += pg_constraint >= 1\n",
    "    lp += sg_constraint >= 1\n",
    "    lp += sf_constraint >= 1\n",
    "    lp += pf_constraint >= 1\n",
    "    lp += c_constraint >= 1\n",
    "    lp += g_constraint <= 4\n",
    "    lp += f_constraint <= 4\n",
    "    lp += g_constraint >= 3\n",
    "    lp += f_constraint >= 3\n",
    "    lp += c_constraint <= 2\n",
    "    lp += player_constraint == 8\n",
    "    \n",
    "    cost = sum(np.array(costs) * np.array(list(d.values())))\n",
    "    lp += cost <= budget\n",
    "    \n",
    "    lp.solve()\n",
    "    \n",
    "    lineup = [variable.name for variable in lp.variables() if variable.varValue == 1]\n",
    "    return lineup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_scores_for_range_of_days(start_date, end_date):\n",
    "    all_tables = []\n",
    "    start_month = start_date.month\n",
    "    end_month = end_date.month\n",
    "    start_year = start_date.year\n",
    "    end_year = end_date.year\n",
    "    \n",
    "    for y in range(start_year, end_year + 1):\n",
    "        sm, em = 1, 12\n",
    "        if y == start_year:\n",
    "            sm = start_month\n",
    "        if y == end_year:\n",
    "            em = end_month\n",
    "        for m in range(sm, em + 1):\n",
    "            if m == start_month and y == start_year:\n",
    "                start_day = start_date.day\n",
    "            else:\n",
    "                start_day = 1\n",
    "            if m == end_month and y == end_year:\n",
    "                end_day = end_date.day\n",
    "            else:\n",
    "                if m == 2:\n",
    "                    end_day = 29\n",
    "                elif m in [9, 4, 6, 11]:\n",
    "                    end_day = 30\n",
    "                else:\n",
    "                    end_day = 31\n",
    "        \n",
    "            for d in range(start_day, end_day + 1):\n",
    "                file_name = \"./AllCSVs/{0}_{1}_{2}_box_scores.csv\".format(m, d, y)\n",
    "                if not path.exists(file_name):\n",
    "                    continue\n",
    "                if pd.read_csv(file_name).empty:\n",
    "                    client.player_box_scores(day=d, month=m, year=y, output_type=OutputType.CSV, output_file_path=file_name)\n",
    "                table = pd.read_csv(file_name)\n",
    "                date = datetime(y, m, d)\n",
    "                dates = [date] * len(table)\n",
    "                table[\"Date\"] = dates\n",
    "                all_tables.append(table)\n",
    "\n",
    "    full_df = all_tables[0]\n",
    "    for i in range(1, len(all_tables)):\n",
    "        current_table = all_tables[i]\n",
    "        full_df = full_df.append(current_table)\n",
    "    \n",
    "    full_df.index = range(full_df.shape[0])\n",
    "    df = pd.read_csv(\"./OutputCSVs/updated_team_stats.csv\")\n",
    "    df[\"team\"] = df[\"team\"].str.upper()\n",
    "\n",
    "    team_def = []\n",
    "    team_pace = []\n",
    "    team_tov = []\n",
    "    opp_def = []\n",
    "    opp_pace = []\n",
    "    opp_tov = []\n",
    "    all_games_teams = full_df[[\"team\", \"opponent\"]]\n",
    "\n",
    "    for i in range(len(all_games_teams)):\n",
    "        game = all_games_teams.loc[i]\n",
    "        team = game[\"team\"].upper()\n",
    "        opponent = game[\"opponent\"].upper()\n",
    "        team_def.append(df[df[\"team\"] == team][\"drtg\"].iloc[0])\n",
    "        team_pace.append(df[df[\"team\"] == team][\"pace\"].iloc[0])\n",
    "        team_tov.append(df[df[\"team\"] == team][\"tov%\"].iloc[0])\n",
    "        opp_def.append(df[df[\"team\"] == opponent][\"drtg\"].iloc[0])\n",
    "        opp_pace.append(df[df[\"team\"] == opponent][\"pace\"].iloc[0])\n",
    "        opp_tov.append(df[df[\"team\"] == opponent][\"tov%\"].iloc[0])\n",
    "    \n",
    "    full_df[\"Team Defensive Rating\"] = team_def\n",
    "    full_df[\"Team Pace\"] = team_pace\n",
    "    full_df[\"Team Turnover %\"] = team_tov\n",
    "    full_df[\"Opponent Defensive Rating\"] = opp_def\n",
    "    full_df[\"Opponent Pace\"] = opp_pace\n",
    "    full_df[\"Opponent Turnover %\"] = opp_tov\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(start_date, end_date, output = True):\n",
    "    input_statistics = [\"name\", \"team\", \"date\", \"location\", \"opponent\", \"made_field_goals\", \"made_two_point_field_goals\", \"attempted_two_point_field_goals\", \"attempted_field_goals\", \"made_three_point_field_goals\", \"attempted_three_point_field_goals\", \"attempted_free_throws\", \"made_free_throws\", \"offensive_rebounds\", \"defensive_rebounds\", \"assists\", \"blocks\", \"turnovers\", \"steals\", \"seconds_played\", \"Opponent Defensive Rating\", \"Opponent Turnover %\", 'Team Defensive Rating', 'Team Pace', 'Team Turnover %', 'Opponent Pace']\n",
    "    full_df = box_scores_for_range_of_days(start_date, end_date)\n",
    "    predicted_statlines = statline_output(full_df, input_statistics)\n",
    "    if output:\n",
    "        output_filename = './AllCSVs/' + str(start_date.month) + '_' + str(start_date.day) + '_' + str(end_date.month) + '_' + str(end_date.day) + '_' + str(end_date.year) + '_predicted_box_scores.csv'\n",
    "        predicted_statlines.to_csv(output_filename)\n",
    "    return predicted_statlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day(start_date, game_date):\n",
    "    season_schedule = client.season_schedule(season_end_year = game_date.year)\n",
    "    schedule_on_date = [game for game in season_schedule if (game['start_time'] - timedelta(hours = 4)).day == game_date.day and game['start_time'].month == game_date.month]\n",
    "    team_objs_on_date = [game[\"home_team\"] for game in schedule_on_date] + [game[\"away_team\"] for game in schedule_on_date]\n",
    "    teams_on_date = [t.name.replace(\"_\", \" \") for t in team_objs_on_date]\n",
    "    predictions_for_date = make_predictions(start_date, game_date, output = False)\n",
    "    players_on_date = predictions_for_date[predictions_for_date.team.isin(teams_on_date)]\n",
    "    mstr, dstr = str(game_date.month), str(game_date.day)\n",
    "    if game_date.month < 10:\n",
    "        mstr = \"0\" + mstr\n",
    "    if game_date.day < 10:\n",
    "        dstr = \"0\" + dstr\n",
    "    tstr = mstr + \"-\" + dstr\n",
    "    statlines_on_date = players_on_date[players_on_date.date.str.contains(tstr)]\n",
    "    statlines_on_date.index = range(statlines_on_date.shape[0])\n",
    "    output_filename = './AllCSVs/predictions_for_' + mstr + \"_\" + dstr + '_from_' + str(start_date.month) + '_' + str(start_date.day) + '_' + str(start_date.year) + '.csv'\n",
    "    statlines_on_date.to_csv(output_filename)\n",
    "    return statlines_on_date\n",
    "#feb_28_predictions = predict_next_day(datetime(2020, 1, 27), datetime(2020, 2, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_actual_results(start_date, game_date):\n",
    "    predicted_results = predict_next_day(start_date, game_date)\n",
    "    actual_results = box_scores_for_range_of_days(game_date, game_date)\n",
    "    actual_results[\"made_two_point_field_goals\"] = actual_results[\"made_field_goals\"] - actual_results[\"made_three_point_field_goals\"]\n",
    "    actual_results[\"rebounds\"] = actual_results[\"offensive_rebounds\"] + actual_results[\"defensive_rebounds\"]\n",
    "    pred_outputs = [float(get_points(predicted_results[predicted_results[\"name\"] == player_name])[0]) for player_name in predicted_results[\"name\"]]\n",
    "    actual_outputs = [float(get_points(actual_results[actual_results[\"name\"] == player_name])[0]) for player_name in predicted_results[\"name\"]]\n",
    "    predicted_results[\"predicted_points\"] = pred_outputs\n",
    "    predicted_results[\"actual_points\"] = actual_outputs\n",
    "    output_filename = './AllCSVs/' + str(game_date.month) + '_' + str(game_date.day) + '_' + str(game_date.year) + '_box_scores_predicted_with_actual.csv'\n",
    "    predicted_results.to_csv(output_filename)\n",
    "    return predicted_results\n",
    "\n",
    "#append_actual_results(datetime(2020, 2, 1), datetime(2020, 2, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternate_contests(start_date, game_date, search_datetime, inclusive):\n",
    "    season_schedule = client.season_schedule(season_end_year = game_date.year)\n",
    "    schedule_on_date = [game for game in season_schedule if (game['start_time'] - timedelta(hours = 4)).day == game_date.day and (game['start_time'] - timedelta(hours = 4)).month == game_date.month]\n",
    "    times_on_date = np.unique([game['start_time'] - timedelta(hours = 4) for game in schedule_on_date])\n",
    "    print(times_on_date)\n",
    "    if not inclusive:\n",
    "        game_teams = [game[\"home_team\"] for game in schedule_on_date if (game['start_time'] - timedelta(hours = 4)) == search_datetime] + [game[\"away_team\"] for game in schedule_on_date if (game['start_time'] - timedelta(hours = 4)) == search_datetime]\n",
    "    else:\n",
    "        times_after_search = [t for t in times_on_date if 60 * t.hour + t.minute >= 60 * search_datetime.hour + search_datetime.minute]\n",
    "        game_teams = [game[\"home_team\"] for game in schedule_on_date if (game['start_time'] - timedelta(hours = 4)) in times_after_search] + [game[\"away_team\"] for game in schedule_on_date if (game['start_time'] - timedelta(hours = 4)) in times_after_search]\n",
    "    game_team_strings = [str(team)[5:].replace(\"_\", \" \") for team in game_teams]\n",
    "    predictions_for_date = predict_next_day(start_date, game_date)\n",
    "    players_on_date = predictions_for_date[predictions_for_date.team.isin(game_team_strings)]\n",
    "    output_filename = './AllCSVs/' + str(game_date.month) + '_' + str(game_date.day) + '_' + str(game_date.year) + '_alternate_' + str(search_datetime.hour) + \"_\" + str(search_datetime.minute) + '.csv'\n",
    "    players_on_date.to_csv(output_filename)\n",
    "    return players_on_date\n",
    "#alternate_contests(datetime(2020, 1, 1), datetime(2020, 1, 13), datetime(2020, 1, 13, 21, 30), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:119: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:119: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def matchup_lookup(matchups, team):\n",
    "    matchup = [m for m in matchups if team in m][0]\n",
    "    if team == matchup[0]:\n",
    "        return matchup[1]\n",
    "    else:\n",
    "        return matchup[0]\n",
    "\n",
    "def predict_unplayed_games(start_date, game_date):\n",
    "    season_schedule = client.season_schedule(season_end_year = game_date.year)\n",
    "    schedule_on_date = [game for game in season_schedule if (game['start_time'] - timedelta(hours = 4)).day == game_date.day and (game['start_time'] - timedelta(hours = 4)).month == game_date.month]\n",
    "    available_box_scores = box_scores_for_range_of_days(start_date, game_date)\n",
    "    game_teams = [game[\"home_team\"] for game in schedule_on_date] + [game[\"away_team\"] for game in schedule_on_date]\n",
    "    matchups = [[str(game[\"home_team\"])[5:].replace(\"_\", \" \"), str(game[\"away_team\"])[5:].replace(\"_\", \" \")] for game in schedule_on_date]\n",
    "    game_team_strings = [str(team)[5:].replace(\"_\", \" \") for team in game_teams]\n",
    "    relevant_lines = available_box_scores[available_box_scores.team.isin(game_team_strings)]\n",
    "    relevant_players = relevant_lines.drop_duplicates(subset = [\"name\"])\n",
    "    mstr, dstr = str(game_date.month), str(game_date.day)\n",
    "    if game_date.month < 10:\n",
    "        mstr = \"0\" + mstr\n",
    "    if game_date.day < 10:\n",
    "        dstr = \"0\" + dstr\n",
    "    tstr = str(game_date.year) + \"-\" + mstr + \"-\" + dstr\n",
    "    relevant_players.Date = [tstr for _ in range(len(relevant_players))]\n",
    "    relevant_players.location = [\"AWAY\" for _ in range(len(relevant_players))]\n",
    "    relevant_players.opponent = [matchup_lookup(matchups, t) for t in relevant_players.team]\n",
    "    augmented_box_scores = available_box_scores.append(relevant_players)\n",
    "    augmented_box_scores.index = range(augmented_box_scores.shape[0])\n",
    "    predicted_statlines = statline_output(augmented_box_scores, input_statistics)\n",
    "    statlines_on_date = predicted_statlines[predicted_statlines.date.str.contains(tstr)]\n",
    "    statlines_on_date['projected_points'] = [round(float(get_points(statlines_on_date[statlines_on_date[\"name\"] == player_name])[0]), 2) for player_name in statlines_on_date.name]\n",
    "    statlines_on_date['projected_points_draftkings'] = [round(float(get_draftkings_points(statlines_on_date[statlines_on_date[\"name\"] == player_name])[0]), 2) for player_name in statlines_on_date.name]\n",
    "    statlines_on_date['projected_value'] = [round(float(get_points(statlines_on_date[statlines_on_date[\"name\"] == player_name])[1])) for player_name in statlines_on_date.name]\n",
    "    statlines_on_date['projected_value_draftkings'] = [round(float(get_draftkings_points(statlines_on_date[statlines_on_date[\"name\"] == player_name])[1])) for player_name in statlines_on_date.name]\n",
    "    output_filename = './AllCSVs/predictions_for_' + mstr + \"_\" + dstr + \"_\" + str(game_date.year) + \"_unplayed.csv\"\n",
    "    statlines_on_date.to_csv(output_filename)\n",
    "    return statlines_on_date\n",
    "\n",
    "july_30_predictions = predict_unplayed_games(datetime(2020, 1, 2), datetime(2020, 7, 30))\n",
    "# # july_30_predictions\n",
    "july_31_predictions = predict_unplayed_games(datetime(2020, 1, 2), datetime(2020, 7, 31))\n",
    "# july_31_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests(sport=Sport.NBA)\n",
    "# draftables(draft_group_id=4)\n",
    "# draft_group_details(draft_group_id=1)\n",
    "# available_players(draft_group_id=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficult_names_map_fanduel = {\"Luka Doni\": \"Luka Doncic\", \n",
    "                       \"Luka amani\": \"Luka Samanic\", \n",
    "                       \"Kristaps Porziis\": \"Kristaps Porzingis\", \n",
    "                       \"Nikola Vuevi\": \"Nikola Vucevic\",\n",
    "                       \"Jonas Valaninas\": \"Jonas Valanciunas\",\n",
    "                       \"Bogdan Bogdanovi\": \"Bogdan Bogdanovic\",\n",
    "                       \"Dario ari\": \"Dario Saric\",\n",
    "                       \"Timoth Luwawu-Cabarrot\": \"Timothe Luwawu-Cabarrot\",\n",
    "                       \"Danan Musa\": \"Dzanan Musa\",\n",
    "                        \"Dvis Bertns\": \"Davis Bertans\",\n",
    "                        \"Boban Marjanovi\": \"Boban Marjanovic\",\n",
    "                        \"Ersan lyasova\": \"Ersan Ilyasova\",\n",
    "                        \"Anejs Paseiks\": \"Anzejs Pasecniks\",\n",
    "                       \"Bojan Bogdanovi\": \"Bojan Bogdanovic\",\n",
    "                        \"Nicol Melli\": \"Nicolo Melli\",\n",
    "                       \"Gary Payton\": \"Gary Payton II\",\n",
    "                       \"Mohamed Bamba\": \"Mo Bamba\",\n",
    "                       \"Wesley Iwundu\": \"Wes Iwundu\",\n",
    "                        \"J.J. Redick\": \"JJ Redick\",\n",
    "                        \"B.J. Johnson\": \"BJ Johnson\"} #Check this for August 1\n",
    "\n",
    "difficult_names_map_draftkings = {\"Luka Doni\": \"Luka Doncic\", \n",
    "                       \"Luka amani\": \"Luka Samanic\", \n",
    "                       \"Kristaps Porziis\": \"Kristaps Porzingis\", \n",
    "                       \"Nikola Vuevi\": \"Nikola Vucevic\",\n",
    "                       \"Jonas Valaninas\": \"Jonas Valanciunas\",\n",
    "                       \"Bogdan Bogdanovi\": \"Bogdan Bogdanovic\",\n",
    "                       \"Dario ari\": \"Dario Saric\",\n",
    "                       \"Timoth Luwawu-Cabarrot\": \"Timothe Luwawu-Cabarrot\",\n",
    "                       \"Danan Musa\": \"Dzanan Musa\",\n",
    "                        \"Boban Marjanovi\": \"Boban Marjanovic\",\n",
    "                        \"Ersan lyasova\": \"Ersan Ilyasova\",\n",
    "                        \"Anejs Paseiks\": \"Anzejs Pasecniks\",\n",
    "                       \"Bojan Bogdanovi\": \"Bojan Bogdanovic\",\n",
    "                        \"Dvis Bertns\": \"Davis Bertans\",\n",
    "                        \"Nicol Melli\": \"Nicolo Melli\",\n",
    "                       \"Gary Payton\": \"Gary Payton II\",\n",
    "                       \"Frank Mason\": \"Frank Mason III\",\n",
    "                       \"Marvin Bagley\": \"Marvin Bagley III\",\n",
    "                       \"James Ennis\": \"James Ennis III\",\n",
    "                       \"Harry Giles\": \"Harry Giles III\",\n",
    "                        \"Lonnie Walker\": \"Lonnie Walker IV\",\n",
    "                       \"Mohamed Bamba\": \"Mo Bamba\",\n",
    "                       \"Wesley Iwundu\": \"Wes Iwundu\",\n",
    "                        \"J.J. Redick\": \"JJ Redick\",\n",
    "                        \"B.J. Johnson\": \"BJ Johnson\",\n",
    "                        \"Melvin Frazier\": \"Melvin Frazier Jr.\",\n",
    "                        \"Gary Trent\": \"Gary Trent Jr.\",\n",
    "                        \"Danuel House\": \"Danuel House Jr.\",\n",
    "                        \"Tim Hardaway\": \"Tim Hardaway Jr.\",\n",
    "                        \"Jaren Jackson\": \"Jaren Jackson Jr.\",\n",
    "                        \"Kelly Oubre\": \"Kelly Oubre Jr.\",\n",
    "                        \"Troy Brown\": \"Troy Brown Jr.\",\n",
    "                        \"Marcus Morris\": \"Marcus Morris Sr.\"} #Check this for August 1\n",
    "\n",
    "punctuation_names = {\"Kentavious Caldwell Pope\": \"Kentavious Caldwell-Pope\",\n",
    "                    \"Marcus Morris Sr.\": \"Marcus Morris\"}\n",
    "\n",
    "#august_1_predictions = predict_unplayed_games(datetime(2020, 1, 2), datetime(2020, 8, 1))\n",
    "#august_1_predictions[august_1_predictions[\"team\"].str.contains(\"PHI\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done predicting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\waldm\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pulp\\pulp.py:1137: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Position</th>\n",
       "      <th>Game</th>\n",
       "      <th>Team</th>\n",
       "      <th>Projected Fanduel Points</th>\n",
       "      <th>Projected Fanduel Value</th>\n",
       "      <th>Fanduel Salary</th>\n",
       "      <th>Value above Fanduel Value</th>\n",
       "      <th>FPPG (Fanduel)</th>\n",
       "      <th>Injury Indicator</th>\n",
       "      <th>Injury Details</th>\n",
       "      <th>Hot</th>\n",
       "      <th>Cold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Donovan Mitchell</td>\n",
       "      <td>SG</td>\n",
       "      <td>UTA@NO</td>\n",
       "      <td>UTA</td>\n",
       "      <td>30.04</td>\n",
       "      <td>$6007</td>\n",
       "      <td>$7200</td>\n",
       "      <td>-$1193</td>\n",
       "      <td>36.10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.987174</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Josh Hart</td>\n",
       "      <td>SG</td>\n",
       "      <td>UTA@NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>24.68</td>\n",
       "      <td>$4937</td>\n",
       "      <td>$4400</td>\n",
       "      <td>$537</td>\n",
       "      <td>23.49</td>\n",
       "      <td>GTD</td>\n",
       "      <td>Face</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.607648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>SF</td>\n",
       "      <td>LAC@LAL</td>\n",
       "      <td>LAC</td>\n",
       "      <td>45.76</td>\n",
       "      <td>$9152</td>\n",
       "      <td>$9500</td>\n",
       "      <td>-$348</td>\n",
       "      <td>47.63</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>SF</td>\n",
       "      <td>UTA@NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>32.66</td>\n",
       "      <td>$6533</td>\n",
       "      <td>$7300</td>\n",
       "      <td>-$767</td>\n",
       "      <td>38.81</td>\n",
       "      <td>GTD</td>\n",
       "      <td>Face</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lonzo Ball</td>\n",
       "      <td>PG</td>\n",
       "      <td>UTA@NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>36.22</td>\n",
       "      <td>$7243</td>\n",
       "      <td>$7900</td>\n",
       "      <td>-$657</td>\n",
       "      <td>32.61</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Alex Caruso</td>\n",
       "      <td>PG</td>\n",
       "      <td>LAC@LAL</td>\n",
       "      <td>LAL</td>\n",
       "      <td>22.44</td>\n",
       "      <td>$4487</td>\n",
       "      <td>$3500</td>\n",
       "      <td>$987</td>\n",
       "      <td>13.59</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>PF</td>\n",
       "      <td>LAC@LAL</td>\n",
       "      <td>LAL</td>\n",
       "      <td>58.83</td>\n",
       "      <td>$11766</td>\n",
       "      <td>$10400</td>\n",
       "      <td>$1366</td>\n",
       "      <td>51.92</td>\n",
       "      <td>GTD</td>\n",
       "      <td>Eye</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Zylan Cheatham</td>\n",
       "      <td>PF</td>\n",
       "      <td>UTA@NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>22.57</td>\n",
       "      <td>$4513</td>\n",
       "      <td>$3500</td>\n",
       "      <td>$1013</td>\n",
       "      <td>4.73</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Montrezl Harrell</td>\n",
       "      <td>C</td>\n",
       "      <td>LAC@LAL</td>\n",
       "      <td>LAC</td>\n",
       "      <td>35.22</td>\n",
       "      <td>$7044</td>\n",
       "      <td>$6300</td>\n",
       "      <td>$744</td>\n",
       "      <td>33.23</td>\n",
       "      <td>GTD</td>\n",
       "      <td>Personal</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name Position     Game Team  Projected Fanduel Points  \\\n",
       "8   Donovan Mitchell       SG   UTA@NO  UTA                     30.04   \n",
       "17         Josh Hart       SG   UTA@NO   NO                     24.68   \n",
       "2      Kawhi Leonard       SF  LAC@LAL  LAC                     45.76   \n",
       "7     Brandon Ingram       SF   UTA@NO   NO                     32.66   \n",
       "5         Lonzo Ball       PG   UTA@NO   NO                     36.22   \n",
       "38       Alex Caruso       PG  LAC@LAL  LAL                     22.44   \n",
       "1      Anthony Davis       PF  LAC@LAL  LAL                     58.83   \n",
       "40    Zylan Cheatham       PF   UTA@NO   NO                     22.57   \n",
       "9   Montrezl Harrell        C  LAC@LAL  LAC                     35.22   \n",
       "\n",
       "   Projected Fanduel Value Fanduel Salary Value above Fanduel Value  \\\n",
       "8                    $6007          $7200                    -$1193   \n",
       "17                   $4937          $4400                      $537   \n",
       "2                    $9152          $9500                     -$348   \n",
       "7                    $6533          $7300                     -$767   \n",
       "5                    $7243          $7900                     -$657   \n",
       "38                   $4487          $3500                      $987   \n",
       "1                   $11766         $10400                     $1366   \n",
       "40                   $4513          $3500                     $1013   \n",
       "9                    $7044          $6300                      $744   \n",
       "\n",
       "    FPPG (Fanduel) Injury Indicator Injury Details       Hot      Cold  \n",
       "8            36.10                                  0.987174  0.000000  \n",
       "17           23.49              GTD           Face  0.000000  1.607648  \n",
       "2            47.63                                  0.000000  0.000000  \n",
       "7            38.81              GTD           Face  0.000000  0.000000  \n",
       "5            32.61                                  0.000000  0.000000  \n",
       "38           13.59                                  0.000000  0.000000  \n",
       "1            51.92              GTD            Eye  0.000000  0.000000  \n",
       "40            4.73                                  0.000000  0.000000  \n",
       "9            33.23              GTD       Personal  0.000000  0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimal_lineup_fanduel_games(game_date, predictions, fanduel_csv, players_out = []):\n",
    "    fanduel_data = pd.read_csv(fanduel_csv)\n",
    "    print(\"Done predicting!\")\n",
    "    for i in predictions.index:\n",
    "        if predictions.loc[i, \"name\"] in difficult_names_map_fanduel.keys():\n",
    "            n = predictions.loc[i, \"name\"]\n",
    "            predictions.loc[i, \"name\"] = difficult_names_map_fanduel[n]\n",
    "    fanduel_data_with_predictions = fanduel_data.merge(predictions, left_on = \"Nickname\", right_on = \"name\").fillna(\" \")\n",
    "    fanduel_data_with_predictions[\"FPPG\"] = fanduel_data_with_predictions[\"FPPG\"].round(2)\n",
    "    fanduel_data_with_predictions[\"Value above Market Value\"] = fanduel_data_with_predictions[\"projected_value\"] - fanduel_data_with_predictions[\"Salary\"]\n",
    "    fanduel_data_with_predictions[\"Value above Market Value\"] = np.where(fanduel_data_with_predictions[\"Value above Market Value\"] < 0, '-$' + fanduel_data_with_predictions[\"Value above Market Value\"].astype(str).str[1:], '$' + fanduel_data_with_predictions[\"Value above Market Value\"].astype(str))\n",
    "    fanduel_data_with_predictions_injuries = fanduel_data_with_predictions[fanduel_data_with_predictions[\"Injury Indicator\"] != \"O\"]\n",
    "    players_not_out = [(name not in players_out) for name in fanduel_data_with_predictions_injuries[\"Nickname\"]]\n",
    "    fanduel_data_with_predictions_injuries = fanduel_data_with_predictions_injuries[players_not_out]\n",
    "    fanduel_data_with_predictions_injuries.index = range(fanduel_data_with_predictions_injuries.shape[0])\n",
    "    #print(fanduel_data_with_predictions_injuries)\n",
    "    values = fanduel_data_with_predictions_injuries[\"projected_points\"]\n",
    "    players = fanduel_data_with_predictions_injuries[\"Nickname\"]\n",
    "    positions = fanduel_data_with_predictions_injuries[\"Position\"]\n",
    "    costs = fanduel_data_with_predictions_injuries[\"Salary\"]\n",
    "    data_to_feed = pd.DataFrame(data = {'players': players, 'positions': positions, 'values': values, 'costs': costs})\n",
    "    optimal_lineup = [n.replace(\"_\", \" \") for n in generate_optimal_lineup(players, positions, values, costs, 60000)]\n",
    "    for i in range(len(optimal_lineup)):\n",
    "        if optimal_lineup[i] in punctuation_names.keys():\n",
    "            optimal_lineup[i] = punctuation_names[optimal_lineup[i]]\n",
    "    fanduel_data_with_predictions_injuries[\"projected_value\"] = ['$' + str(s) for s in fanduel_data_with_predictions_injuries[\"projected_value\"]]\n",
    "    fanduel_data_with_predictions_injuries[\"Salary\"] = ['$' + str(s) for s in fanduel_data_with_predictions_injuries[\"Salary\"]]\n",
    "    projs_in_optimal = [(fanduel_data_with_predictions_injuries.loc[i, \"Nickname\"] in optimal_lineup) for i in fanduel_data_with_predictions_injuries.index]\n",
    "    lineup_return = fanduel_data_with_predictions_injuries[projs_in_optimal].sort_values(by=[\"Position\"], ascending = False)\n",
    "    lineup_return = lineup_return.loc[:, [\"Nickname\", \"Position\", \"Game\", \"Team\", 'projected_points', 'projected_value', \"Salary\", \"Value above Market Value\", 'projected_points_draftkings', 'projected_value_draftkings', \"FPPG\", '10_game_average', '3_game_average', \"Injury Indicator\", \"Injury Details\", \"minutes\", \"made_two_point_field_goals\", 'made_three_point_field_goals',\n",
    "       'made_free_throws', 'rebounds', 'assists', 'blocks', 'steals', 'turnovers','hot', 'cold']]\n",
    "    lineup_return.columns = [\"Name\", \"Position\", \"Game\", \"Team\", 'Projected Fanduel Points', 'Projected Fanduel Value', \"Fanduel Salary\",  \"Value above Fanduel Value\", 'Projected Draftkings Points', 'Projected Draftkings Value', \"FPPG (Fanduel)\", '10 Game Average (Fanduel)', '3 Game Average (Fanduel)', \"Injury Indicator\", \"Injury Details\", \"Minutes\", \"2PT FG\", '3PT FG',\n",
    "       'FTM', 'Rebounds', 'Assists', 'Blocks', 'Steals', 'Turnovers','Hot', 'Cold']\n",
    "    csv_return = fanduel_data_with_predictions.loc[:, [\"Nickname\", \"Position\", \"Game\", \"Team\", 'projected_points', 'projected_value', \"Salary\", \"Value above Market Value\", 'projected_points_draftkings', 'projected_value_draftkings', \"FPPG\", '10_game_average', '3_game_average', \"Injury Indicator\", \"Injury Details\", \"minutes\", \"made_two_point_field_goals\", 'made_three_point_field_goals',\n",
    "       'made_free_throws', 'rebounds', 'assists', 'blocks', 'steals', 'turnovers', \"Opponent Defensive Rank vs Position\", 'hot', 'cold']]\n",
    "    csv_return.columns = [\"Name\", \"Position\", \"Game\", \"Team\", 'Projected Fanduel Points', 'Projected Fanduel Value', \"Fanduel Salary\", \"Value above Fanduel Value\", 'Projected Draftkings Points', 'Projected Draftkings Value', \"FPPG (Fanduel)\", '10 Game Average (Fanduel)', '3 Game Average (Fanduel)', \"Injury Indicator\", \"Injury Details\", \"Minutes\", \"2PT FG\", '3PT FG',\n",
    "       'FTM', 'Rebounds', 'Assists', 'Blocks', 'Steals', 'Turnovers', \"Opponent Defensive Rank vs Position\", 'Hot', 'Cold']\n",
    "    csv_return_dfs = csv_return.loc[:, [\"Name\", \"Position\", \"Game\", \"Team\", 'Projected Fanduel Points', 'Projected Fanduel Value', \"Fanduel Salary\", \"Value above Fanduel Value\", 'Projected Draftkings Points', 'Projected Draftkings Value', \"FPPG (Fanduel)\", '10 Game Average (Fanduel)', '3 Game Average (Fanduel)', \"Opponent Defensive Rank vs Position\",  \"Injury Indicator\", \"Injury Details\", 'Hot', 'Cold']]\n",
    "    csv_return_projections = csv_return.loc[:, [\"Name\", \"Position\", \"Game\", \"Team\", \"Minutes\", \"2PT FG\", '3PT FG',\n",
    "       'FTM', 'Rebounds', 'Assists', 'Blocks', 'Steals', 'Turnovers', \"Opponent Defensive Rank vs Position\", \"Injury Indicator\", \"Injury Details\"]]\n",
    "    lineup_return = lineup_return.loc[:, [\"Name\", \"Position\", \"Game\", \"Team\", 'Projected Fanduel Points', 'Projected Fanduel Value', \"Fanduel Salary\", \"Value above Fanduel Value\", \"FPPG (Fanduel)\", \"Injury Indicator\", \"Injury Details\", 'Hot', 'Cold']]\n",
    "    \n",
    "    csv_return_dfs.to_csv(\"./AllCSVs/dfs_projections_to_display_\" + str(game_date.month) + \"_\" + str(game_date.day) + \"_\" + str(game_date.year) + \".csv\")\n",
    "    csv_return_projections.to_csv(\"./AllCSVs/statline_projections_to_display_\" + str(game_date.month) + \"_\" + str(game_date.day) + \"_\" + str(game_date.year) + \".csv\")\n",
    "    lineup_return.to_csv(\"./AllCSVs/optimal_fanduel_lineup_\" + str(game_date.month) + \"_\" + str(game_date.day) + \"_\" + str(game_date.year) + \".csv\")\n",
    "    return csv_return_dfs, csv_return_projections, lineup_return\n",
    "\n",
    "def optimal_lineup_draftkings_games(game_date, predictions, draftkings_csv, players_out = []):\n",
    "    draftkings_data = pd.read_csv(draftkings_csv)\n",
    "    print(\"Done predicting!\")\n",
    "    for i in predictions.index:\n",
    "        if predictions.loc[i, \"name\"] in difficult_names_map_draftkings.keys():\n",
    "            n = predictions.loc[i, \"name\"]\n",
    "            predictions.loc[i, \"name\"] = difficult_names_map_draftkings[n]\n",
    "    draftkings_data_with_predictions = draftkings_data.merge(predictions, left_on = \"Name\", right_on = \"name\")\n",
    "    draftkings_data_with_predictions[\"AvgPointsPerGame\"] = draftkings_data_with_predictions[\"AvgPointsPerGame\"].round(2)\n",
    "    draftkings_data_with_predictions[\"Game Info\"] = [g[:7] for g in draftkings_data_with_predictions[\"Game Info\"]]\n",
    "    draftkings_data_with_predictions[\"Value above Market Value\"] = draftkings_data_with_predictions[\"projected_value_draftkings\"] - draftkings_data_with_predictions[\"Salary\"]\n",
    "    draftkings_data_with_predictions[\"Value above Market Value\"] = np.where(draftkings_data_with_predictions[\"Value above Market Value\"] < 0, '-$' + draftkings_data_with_predictions[\"Value above Market Value\"].astype(str).str[1:], '$' + draftkings_data_with_predictions[\"Value above Market Value\"].astype(str))\n",
    "    draftkings_data_with_predictions_injuries = draftkings_data_with_predictions#[draftkings_data_with_predictions[\"Injury Indicator\"] != \"O\"]\n",
    "    players_not_out = [(name not in players_out) for name in draftkings_data_with_predictions_injuries[\"Name\"]]\n",
    "    draftkings_data_with_predictions_injuries = draftkings_data_with_predictions_injuries[players_not_out]\n",
    "    draftkings_data_with_predictions_injuries.index = range(draftkings_data_with_predictions_injuries.shape[0])\n",
    "    #print(fanduel_data_with_predictions_injuries)\n",
    "    values = draftkings_data_with_predictions_injuries[\"projected_points_draftkings\"]\n",
    "    players = draftkings_data_with_predictions_injuries[\"Name\"]\n",
    "    positions_as_lists = [list(st.split(\"/\")) for st in draftkings_data_with_predictions_injuries[\"Position\"]]\n",
    "    positions = draftkings_data_with_predictions_injuries[\"Position\"]\n",
    "    costs = draftkings_data_with_predictions_injuries[\"Salary\"]\n",
    "    data_to_feed = pd.DataFrame(data = {'players': players, 'positions': positions_as_lists, 'values': values, 'costs': costs})\n",
    "    optimal_lineup = [n.replace(\"_\", \" \") for n in generate_optimal_lineup_draftkings(players, positions_as_lists, values, costs, 50000)]\n",
    "    for i in range(len(optimal_lineup)):\n",
    "        if optimal_lineup[i] in punctuation_names.keys():\n",
    "            optimal_lineup[i] = punctuation_names[optimal_lineup[i]]\n",
    "    draftkings_data_with_predictions_injuries[\"projected_value_draftkings\"] = ['$' + str(s) for s in draftkings_data_with_predictions_injuries[\"projected_value_draftkings\"]]\n",
    "    draftkings_data_with_predictions_injuries[\"Salary\"] = ['$' + str(s) for s in draftkings_data_with_predictions_injuries[\"Salary\"]]\n",
    "    projs_in_optimal = [(draftkings_data_with_predictions_injuries.loc[i, \"Name\"] in optimal_lineup) for i in draftkings_data_with_predictions_injuries.index]\n",
    "    lineup_return = draftkings_data_with_predictions_injuries[projs_in_optimal].sort_values(by=[\"Position\"], ascending = False)\n",
    "    lineup_return = lineup_return.loc[:, [\"Name\", \"Position\", \"Game Info\", \"TeamAbbrev\", 'projected_points', 'projected_value', 'projected_points_draftkings', 'projected_value_draftkings', \"Salary\", \"Value above Market Value\", \"AvgPointsPerGame\", '10_game_average', '3_game_average', \"Injury Indicator\", \"Injury Details\", \"minutes\", \"made_two_point_field_goals\", 'made_three_point_field_goals',\n",
    "       'made_free_throws', 'rebounds', 'assists', 'blocks', 'steals', 'turnovers','hot', 'cold']].fillna(\" \")\n",
    "    lineup_return.columns = [\"Name\", \"Position\", \"Game\", \"Team\", 'Projected Fanduel Points', 'Projected Fanduel Value', 'Projected Draftkings Points', 'Projected Draftkings Value', \"Draftkings Salary\", \"Value above Draftkings Value\", \"FPPG\", '10 Game Average (Fanduel)', '3 Game Average (Fanduel)', \"Injury Indicator\", \"Injury Details\", \"Minutes\", \"2PT FG\", '3PT FG',\n",
    "       'FTM', 'Rebounds', 'Assists', 'Blocks', 'Steals', 'Turnovers','Hot', 'Cold']\n",
    "    csv_return = draftkings_data_with_predictions.loc[:, [\"Name\", \"Position\", \"Salary\", \"Game Info\", \"TeamAbbrev\", 'projected_points', 'projected_value', \"Value above Market Value\", 'projected_points_draftkings', 'projected_value_draftkings', \"AvgPointsPerGame\", '10_game_average', '3_game_average', \"Injury Indicator\", \"Injury Details\", \"minutes\", \"made_two_point_field_goals\", 'made_three_point_field_goals',\n",
    "       'made_free_throws', 'rebounds', 'assists', 'blocks', 'steals', 'turnovers', \"Opponent Defensive Rank vs Position\", 'hot', 'cold']].fillna(\" \")\n",
    "    csv_return.columns = [\"Name\", \"Position\", \"Salary\", \"Game\", \"Team\", 'Projected Fanduel Points', 'Projected Fanduel Value', \"Value above Fanduel Value\", 'Projected Draftkings Points', 'Projected Draftkings Value', \"FPPG\", '10 Game Average (Fanduel)', '3 Game Average (Fanduel)', \"Injury Indicator\", \"Injury Details\", \"Minutes\", \"2PT FG\", '3PT FG',\n",
    "       'FTM', 'Rebounds', 'Assists', 'Blocks', 'Steals', 'Turnovers', \"Opponent Defensive Rank vs Position\", 'Hot', 'Cold']\n",
    "    csv_return_dfs = csv_return.loc[:, [\"Name\", \"Position\", \"Salary\", \"Game\", \"Team\", 'Projected Fanduel Points', 'Projected Fanduel Value', \"Value above Fanduel Value\", 'Projected Draftkings Points', 'Projected Draftkings Value', \"FPPG\", '10 Game Average (Fanduel)', '3 Game Average (Fanduel)', \"Opponent Defensive Rank vs Position\", \"Injury Indicator\", \"Injury Details\", 'Hot', 'Cold']]\n",
    "    csv_return_projections = csv_return.loc[:, [\"Name\", \"Position\", \"Game\", \"Team\", \"Minutes\", \"2PT FG\", '3PT FG',\n",
    "       'FTM', 'Rebounds', 'Assists', 'Blocks', 'Steals', 'Turnovers', \"Opponent Defensive Rank vs Position\", \"Injury Indicator\", \"Injury Details\"]]\n",
    "    lineup_return = lineup_return.loc[:, [\"Name\", \"Position\", \"Game\", \"Team\", 'Projected Draftkings Points', 'Projected Draftkings Value', \"Draftkings Salary\", \"Value above Draftkings Value\", \"FPPG\", \"Injury Indicator\", \"Injury Details\", 'Hot', 'Cold']]\n",
    "    \n",
    "    fanduel_statlines = pd.read_csv(\"./AllCSVs/statline_projections_to_display_\" + str(game_date.month) + \"_\" + str(game_date.day) + \"_\" + str(game_date.year) + \".csv\").fillna(\" \")\n",
    "    injury_indicators = []\n",
    "    injury_details = []\n",
    "    for i in lineup_return.index:\n",
    "        print(lineup_return.loc[i, \"Name\"])\n",
    "        for n in fanduel_statlines.index:\n",
    "            if fanduel_statlines.loc[n, \"Name\"] == lineup_return.loc[i, \"Name\"]:\n",
    "                print(i)\n",
    "                injury_indicators.append(fanduel_statlines.loc[n, \"Injury Indicator\"])\n",
    "                injury_details.append(fanduel_statlines.loc[n, \"Injury Details\"])\n",
    "            elif lineup_return.loc[i, \"Name\"] in punctuation_names.keys():\n",
    "                if punctuation_names[lineup_return.loc[i, \"Name\"]] == fanduel_statline.loc[n, \"Name\"]:\n",
    "                    print(i)\n",
    "                    injury_indicators.append(fanduel_statlines.loc[n, \"Injury Indicator\"])\n",
    "                    injury_details.append(fanduel_statlines.loc[n, \"Injury Details\"])\n",
    "    lineup_return[\"Injury Indicator\"] = injury_indicators\n",
    "    lineup_return[\"Injury Details\"] = injury_details\n",
    "    \n",
    "    lineup_return.to_csv(\"./AllCSVs/optimal_draftkings_lineup_\" + str(game_date.month) + \"_\" + str(game_date.day) + \"_\" + str(game_date.year) + \".csv\")\n",
    "    return csv_return_dfs, csv_return_projections, lineup_return\n",
    "\n",
    "preds = pd.read_csv(\"./AllCSVs/predictions_for_07_30_2020_unplayed.csv\")\n",
    "preds_1 = pd.read_csv(\"./AllCSVs/predictions_for_07_31_2020_unplayed.csv\")\n",
    "\n",
    "fd_csv = \"./AllCSVs/FanDuel-NBA-2020-07-30-46677-players-list.csv\"\n",
    "fd_csv_1 = \"./AllCSVs/FanDuel-NBA-2020-07-31-46839-players-list.csv\"\n",
    "\n",
    "dk_csv = \"./AllCSVs/DKSalaries_07302020.csv\"\n",
    "dk_csv_1 = \"./AllCSVs/DKSalaries_07312020.csv\"\n",
    "\n",
    "preds310 = pd.read_csv(\"./AllCSVs/predictions_for_03_10_from_1_19_2020.csv\")\n",
    "preds309 = pd.read_csv(\"./AllCSVs/predictions_for_03_09_from_1_19_2020.csv\")\n",
    "# playerlist730 = pd.read_csv(dk_csv)\n",
    "# print(playerlist731[~playerlist731[\"Name\"].isin(preds_1.name)])\n",
    "# print(playerlist730[~playerlist730[\"Name\"].isin(preds.name)])\n",
    "\n",
    "optimal_lineup_fanduel_games(datetime(2020, 7, 30), preds, fd_csv, [\"Lou Williams\"])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_by_sample(start_date, end_date, sample_size, weight):\n",
    "    full_df = box_scores_for_range_of_days(start_date, end_date)\n",
    "    weighted_statlines = statline_predictor(full_df, input_statistics, sample_size, weight)\n",
    "    weighted_statlines_to_keep = weighted_statlines[weighted_statlines.seconds_played > 1000]\n",
    "    df_to_keep = full_df[weighted_statlines.seconds_played > 1000]\n",
    "    df_to_keep[\"attempted_two_point_field_goals\"] = df_to_keep[\"attempted_field_goals\"] - df_to_keep[\"attempted_three_point_field_goals\"]\n",
    "    df_to_keep[\"made_two_point_field_goals\"] = df_to_keep[\"made_field_goals\"] - df_to_keep[\"made_three_point_field_goals\"]\n",
    "    weighted_statlines_to_keep['name_date'] = weighted_statlines_to_keep[\"name\"] + weighted_statlines_to_keep[\"date\"].astype(str)\n",
    "    df_to_keep['name_date'] = df_to_keep[\"name\"] + df_to_keep[\"Date\"].astype(str)\n",
    "    df_merged = weighted_statlines_to_keep.merge(df_to_keep, left_on = 'name_date', right_on = 'name_date')\n",
    "    df_merged[\"rebounds_y\"] = df_merged[\"offensive_rebounds_y\"] + df_merged[\"defensive_rebounds_y\"]\n",
    "    df_merged[\"location_x\"] = df_merged[\"location_x\"] == \"HOME\"\n",
    "    df_merged[\"location_y\"] = df_merged[\"location_y\"] == \"HOME\"\n",
    "    print(df_merged.columns)\n",
    "    df_merged[\"fantasy_points\"] = [float(get_points(df_merged[df_merged[\"name_date\"] == player_name])[0]) for player_name in df_merged[\"name_date\"]]\n",
    "    df_merged = df_merged[df_merged.Date.astype(str).str.contains(\"2020-02\")]\n",
    "    predictors = df_merged.iloc[:,[3, 51, 52, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50]]\n",
    "    print(df_merged.columns[[3, 51, 52, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50]])\n",
    "    print(len(df_merged.columns), df_merged.columns)\n",
    "    for desired_output in [54]:\n",
    "        y = df_merged.iloc[:,desired_output]\n",
    "        pred_train, pred_test, y_train, y_test = train_test_split(predictors, y, test_size=0.2, random_state=758)\n",
    "        pred_train1, pred_test1, y_train1, y_test1 = train_test_split(predictors, y, test_size=0.2, random_state=3)\n",
    "        pred_train2, pred_test2, y_train2, y_test2 = train_test_split(predictors, y, test_size=0.2, random_state=2690)\n",
    "        pred_train3, pred_test3, y_train3, y_test3 = train_test_split(predictors, y, test_size=0.2, random_state=467)\n",
    "        pred_train4, pred_test4, y_train4, y_test4 = train_test_split(predictors, y, test_size=0.2, random_state=9999)\n",
    "        pred_train5, pred_test5, y_train5, y_test5 = train_test_split(predictors, y, test_size=0.2, random_state=34715)\n",
    "        pred_train6, pred_test6, y_train6, y_test6 = train_test_split(predictors, y, test_size=0.2, random_state=88)\n",
    "        ridge_model = RidgeCV().fit(pred_train, y_train)\n",
    "        linear_model = LinearRegression().fit(pred_train, y_train)\n",
    "        ridge_model1 = RidgeCV().fit(pred_train1, y_train1)\n",
    "        linear_model1 = LinearRegression().fit(pred_train1, y_train1)\n",
    "        ridge_model2 = RidgeCV().fit(pred_train2, y_train2)\n",
    "        linear_model2 = LinearRegression().fit(pred_train2, y_train2)\n",
    "        ridge_model3 = RidgeCV().fit(pred_train3, y_train3)\n",
    "        linear_model3 = LinearRegression().fit(pred_train3, y_train3)\n",
    "        ridge_model4 = RidgeCV().fit(pred_train4, y_train4)\n",
    "        linear_model4 = LinearRegression().fit(pred_train4, y_train4)\n",
    "        ridge_model5 = RidgeCV().fit(pred_train5, y_train5)\n",
    "        linear_model5 = LinearRegression().fit(pred_train5, y_train5)\n",
    "        ridge_model6 = RidgeCV().fit(pred_train6, y_train6)\n",
    "        linear_model6 = LinearRegression().fit(pred_train6, y_train6)\n",
    "        print(df_merged.columns[desired_output])\n",
    "        print(ridge_model.score(pred_test, y_test))\n",
    "        print(linear_model.score(pred_test, y_test))\n",
    "        print(ridge_model1.score(pred_test1, y_test1))\n",
    "        print(linear_model1.score(pred_test1, y_test1))\n",
    "        print(ridge_model2.score(pred_test2, y_test2))\n",
    "        print(linear_model2.score(pred_test2, y_test2))\n",
    "        print(ridge_model3.score(pred_test3, y_test3))\n",
    "        print(linear_model3.score(pred_test3, y_test3))\n",
    "        print(ridge_model4.score(pred_test4, y_test4))\n",
    "        print(linear_model4.score(pred_test4, y_test4))\n",
    "        print(ridge_model5.score(pred_test5, y_test5))\n",
    "        print(linear_model5.score(pred_test5, y_test5))\n",
    "        print(ridge_model6.score(pred_test6, y_test6))\n",
    "        print(linear_model6.score(pred_test6, y_test6))\n",
    "    #return df_merged\n",
    "# for i, j in [(7, .9), (8, .8), (8, .85), (8, .9)]:\n",
    "#         regression_by_sample(datetime(2020, 1, 2), datetime(2020, 2, 29), i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#july_30_predictions.groupby([\"team\"]).sum()\n",
    "#july_30_predictions[july_30_predictions[\"team\"] == \"LOS ANGELES CLIPPERS\"]\n",
    "#sns.distplot(jan_25_pred_actual.predicted_points)\n",
    "#sns.distplot(jan_25_pred_actual.actual_points)\n",
    "#sns.jointplot(data = jan_25_pred_actual, x = \"predicted_points\", y = \"actual_points\", kind = 'reg')\n",
    "#jan_24_pred_actual[\"blended_prediction\"] = .7*jan_24_pred_actual[\"recent_average\"] + .3*jan_24_pred_actual[\"predicted_points\"]\n",
    "#feb_12_pred_actual_sig = feb_12_pred_actual[feb_12_pred_actual[\"minutes\"] <= 19]\n",
    "\n",
    "#print(r2_score(feb_25_pred_actual.fantasy_points_8_9, feb_25_pred_actual.actual_points), r2_score(feb_25_pred_actual.predicted_points, feb_25_pred_actual.actual_points))\n",
    "#print(r2_score(feb_26_pred_actual.fantasy_points_8_9, feb_26_pred_actual.actual_points), r2_score(feb_26_pred_actual.predicted_points, feb_26_pred_actual.actual_points))\n",
    "#print(r2_score(feb_27_pred_actual.fantasy_points_8_9, feb_27_pred_actual.actual_points), r2_score(feb_27_pred_actual.predicted_points, feb_27_pred_actual.actual_points))\n",
    "#print(r2_score(feb_28_pred_actual.fantasy_points_8_9, feb_28_pred_actual.actual_points), r2_score(feb_28_pred_actual.predicted_points, feb_28_pred_actual.actual_points))\n",
    "\n",
    "#sns.jointplot(data = mar_7_pred_actual, x = \"fantasy_points_8_9\", y = \"predicted_points\", kind = 'reg')\n",
    "\n",
    "# print(len(july_30_predictions[july_30_predictions[\"hot\"] > 0])/len(july_30_predictions))\n",
    "# print(len(july_30_predictions[july_30_predictions[\"cold\"] > 0])/len(july_30_predictions))\n",
    "#sns.distplot(july_31_predictions.hot)\n",
    "# july_30_predictions[july_30_predictions[\"hot\"] > 0]\n",
    "#july_31_predictions[july_31_predictions[\"cold\"] > 0]\n",
    "\n",
    "# print(r2_score(mar_1_pred_actual.fantasy_points_7_9, mar_1_pred_actual.actual_points), r2_score(mar_1_pred_actual.fantasy_points_8_8, mar_1_pred_actual.actual_points), r2_score(mar_1_pred_actual.fantasy_points_8_85, mar_1_pred_actual.actual_points), r2_score(mar_1_pred_actual.fantasy_points_8_9, mar_1_pred_actual.actual_points), r2_score(mar_1_pred_actual.predicted_points, mar_1_pred_actual.actual_points))\n",
    "# print(r2_score(mar_2_pred_actual.fantasy_points_7_9, mar_2_pred_actual.actual_points), r2_score(mar_2_pred_actual.fantasy_points_8_8, mar_2_pred_actual.actual_points), r2_score(mar_2_pred_actual.fantasy_points_8_85, mar_2_pred_actual.actual_points), r2_score(mar_2_pred_actual.fantasy_points_8_9, mar_2_pred_actual.actual_points), r2_score(mar_2_pred_actual.predicted_points, mar_2_pred_actual.actual_points))\n",
    "# print(r2_score(mar_3_pred_actual.fantasy_points_7_9, mar_3_pred_actual.actual_points), r2_score(mar_3_pred_actual.fantasy_points_8_8, mar_3_pred_actual.actual_points), r2_score(mar_3_pred_actual.fantasy_points_8_85, mar_3_pred_actual.actual_points), r2_score(mar_3_pred_actual.fantasy_points_8_9, mar_3_pred_actual.actual_points), r2_score(mar_3_pred_actual.predicted_points, mar_3_pred_actual.actual_points))\n",
    "# print(r2_score(mar_4_pred_actual.fantasy_points_7_9, mar_4_pred_actual.actual_points), r2_score(mar_4_pred_actual.fantasy_points_8_8, mar_4_pred_actual.actual_points), r2_score(mar_4_pred_actual.fantasy_points_8_85, mar_4_pred_actual.actual_points), r2_score(mar_4_pred_actual.fantasy_points_8_9, mar_4_pred_actual.actual_points), r2_score(mar_4_pred_actual.predicted_points, mar_4_pred_actual.actual_points))\n",
    "# print(r2_score(mar_5_pred_actual.fantasy_points_7_9, mar_5_pred_actual.actual_points), r2_score(mar_5_pred_actual.fantasy_points_8_8, mar_5_pred_actual.actual_points), r2_score(mar_5_pred_actual.fantasy_points_8_85, mar_5_pred_actual.actual_points), r2_score(mar_5_pred_actual.fantasy_points_8_9, mar_5_pred_actual.actual_points), r2_score(mar_5_pred_actual.predicted_points, mar_5_pred_actual.actual_points))\n",
    "# print(r2_score(mar_6_pred_actual.fantasy_points_7_9, mar_6_pred_actual.actual_points), r2_score(mar_6_pred_actual.fantasy_points_8_8, mar_6_pred_actual.actual_points), r2_score(mar_6_pred_actual.fantasy_points_8_85, mar_6_pred_actual.actual_points), r2_score(mar_6_pred_actual.fantasy_points_8_9, mar_6_pred_actual.actual_points), r2_score(mar_6_pred_actual.predicted_points, mar_6_pred_actual.actual_points))\n",
    "# print(r2_score(mar_7_pred_actual.fantasy_points_7_9, mar_7_pred_actual.actual_points), r2_score(mar_7_pred_actual.fantasy_points_8_8, mar_7_pred_actual.actual_points), r2_score(mar_7_pred_actual.fantasy_points_8_85, mar_7_pred_actual.actual_points), r2_score(mar_7_pred_actual.fantasy_points_8_9, mar_7_pred_actual.actual_points), r2_score(mar_7_pred_actual.predicted_points, mar_7_pred_actual.actual_points))\n",
    "# print(r2_score(mar_8_pred_actual.fantasy_points_7_9, mar_8_pred_actual.actual_points), r2_score(mar_8_pred_actual.fantasy_points_8_8, mar_8_pred_actual.actual_points), r2_score(mar_8_pred_actual.fantasy_points_8_85, mar_8_pred_actual.actual_points), r2_score(mar_8_pred_actual.fantasy_points_8_9, mar_8_pred_actual.actual_points), r2_score(mar_8_pred_actual.predicted_points, mar_8_pred_actual.actual_points))\n",
    "# print(r2_score(mar_9_pred_actual.fantasy_points_7_9, mar_9_pred_actual.actual_points), r2_score(mar_9_pred_actual.fantasy_points_8_8, mar_9_pred_actual.actual_points), r2_score(mar_9_pred_actual.fantasy_points_8_85, mar_9_pred_actual.actual_points), r2_score(mar_9_pred_actual.fantasy_points_8_9, mar_9_pred_actual.actual_points), r2_score(mar_9_pred_actual.predicted_points, mar_9_pred_actual.actual_points))\n",
    "# print(r2_score(mar_10_pred_actual.fantasy_points_7_9, mar_10_pred_actual.actual_points), r2_score(mar_10_pred_actual.fantasy_points_8_8, mar_10_pred_actual.actual_points), r2_score(mar_10_pred_actual.fantasy_points_8_85, mar_10_pred_actual.actual_points), r2_score(mar_10_pred_actual.fantasy_points_8_9, mar_10_pred_actual.actual_points), r2_score(mar_10_pred_actual.predicted_points, mar_10_pred_actual.actual_points))\n",
    "# print(np.mean([r2_score(mar_1_pred_actual.fantasy_points_7_9, mar_1_pred_actual.actual_points), r2_score(mar_2_pred_actual.fantasy_points_7_9, mar_2_pred_actual.actual_points), r2_score(mar_3_pred_actual.fantasy_points_7_9, mar_3_pred_actual.actual_points), r2_score(mar_4_pred_actual.fantasy_points_7_9, mar_4_pred_actual.actual_points), r2_score(mar_5_pred_actual.fantasy_points_7_9, mar_5_pred_actual.actual_points), r2_score(mar_6_pred_actual.fantasy_points_7_9, mar_6_pred_actual.actual_points), r2_score(mar_7_pred_actual.fantasy_points_7_9, mar_7_pred_actual.actual_points), r2_score(mar_8_pred_actual.fantasy_points_7_9, mar_8_pred_actual.actual_points), r2_score(mar_9_pred_actual.fantasy_points_7_9, mar_9_pred_actual.actual_points), r2_score(mar_10_pred_actual.fantasy_points_7_9, mar_10_pred_actual.actual_points)]))\n",
    "# print(np.mean([r2_score(mar_1_pred_actual.fantasy_points_8_8, mar_1_pred_actual.actual_points), r2_score(mar_2_pred_actual.fantasy_points_8_8, mar_2_pred_actual.actual_points), r2_score(mar_3_pred_actual.fantasy_points_8_8, mar_3_pred_actual.actual_points), r2_score(mar_4_pred_actual.fantasy_points_8_8, mar_4_pred_actual.actual_points), r2_score(mar_5_pred_actual.fantasy_points_8_8, mar_5_pred_actual.actual_points), r2_score(mar_6_pred_actual.fantasy_points_8_8, mar_6_pred_actual.actual_points), r2_score(mar_7_pred_actual.fantasy_points_8_8, mar_7_pred_actual.actual_points), r2_score(mar_8_pred_actual.fantasy_points_8_8, mar_8_pred_actual.actual_points), r2_score(mar_9_pred_actual.fantasy_points_8_8, mar_9_pred_actual.actual_points), r2_score(mar_10_pred_actual.fantasy_points_8_8, mar_10_pred_actual.actual_points)]))\n",
    "# print(np.mean([r2_score(mar_1_pred_actual.fantasy_points_8_85, mar_1_pred_actual.actual_points), r2_score(mar_2_pred_actual.fantasy_points_8_85, mar_2_pred_actual.actual_points), r2_score(mar_3_pred_actual.fantasy_points_8_85, mar_3_pred_actual.actual_points), r2_score(mar_4_pred_actual.fantasy_points_8_85, mar_4_pred_actual.actual_points), r2_score(mar_5_pred_actual.fantasy_points_8_85, mar_5_pred_actual.actual_points), r2_score(mar_6_pred_actual.fantasy_points_8_85, mar_6_pred_actual.actual_points), r2_score(mar_7_pred_actual.fantasy_points_8_85, mar_7_pred_actual.actual_points), r2_score(mar_8_pred_actual.fantasy_points_8_85, mar_8_pred_actual.actual_points), r2_score(mar_9_pred_actual.fantasy_points_8_85, mar_9_pred_actual.actual_points), r2_score(mar_10_pred_actual.fantasy_points_8_85, mar_10_pred_actual.actual_points)]))\n",
    "# print(np.mean([r2_score(mar_1_pred_actual.fantasy_points_8_9, mar_1_pred_actual.actual_points), r2_score(mar_2_pred_actual.fantasy_points_8_9, mar_2_pred_actual.actual_points), r2_score(mar_3_pred_actual.fantasy_points_8_9, mar_3_pred_actual.actual_points), r2_score(mar_4_pred_actual.fantasy_points_8_9, mar_4_pred_actual.actual_points), r2_score(mar_5_pred_actual.fantasy_points_8_9, mar_5_pred_actual.actual_points), r2_score(mar_6_pred_actual.fantasy_points_8_9, mar_6_pred_actual.actual_points), r2_score(mar_7_pred_actual.fantasy_points_8_9, mar_7_pred_actual.actual_points), r2_score(mar_8_pred_actual.fantasy_points_8_9, mar_8_pred_actual.actual_points), r2_score(mar_9_pred_actual.fantasy_points_8_9, mar_9_pred_actual.actual_points), r2_score(mar_10_pred_actual.fantasy_points_8_9, mar_10_pred_actual.actual_points)]))\n",
    "# print(np.mean([r2_score(mar_1_pred_actual.predicted_points, mar_1_pred_actual.actual_points), r2_score(mar_2_pred_actual.predicted_points, mar_2_pred_actual.actual_points), r2_score(mar_3_pred_actual.predicted_points, mar_3_pred_actual.actual_points), r2_score(mar_4_pred_actual.predicted_points, mar_4_pred_actual.actual_points), r2_score(mar_5_pred_actual.predicted_points, mar_5_pred_actual.actual_points), r2_score(mar_6_pred_actual.predicted_points, mar_6_pred_actual.actual_points), r2_score(mar_7_pred_actual.predicted_points, mar_7_pred_actual.actual_points), r2_score(mar_8_pred_actual.predicted_points, mar_8_pred_actual.actual_points), r2_score(mar_9_pred_actual.predicted_points, mar_9_pred_actual.actual_points), r2_score(mar_10_pred_actual.predicted_points, mar_10_pred_actual.actual_points)]))\n",
    "#np.mean(jan_24_pred_actual[\"recent_average\"]), np.mean(jan_24_pred_actual[\"predicted_points\"]), np.mean(jan_24_pred_actual[\"actual_points\"])\n",
    "#r2_score(july_31_predictions[\"recent_average\"], july_31_predictions[\"projected_points\"])\n",
    "#r2_score(jan_24_pred_actual[\"recent_average\"], jan_24_pred_actual[\"predicted_points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlisted_players = {\"Jamal Crawford\": [\"SG\", 17],\n",
    "               \"Zach Collins\": [\"C\", 18],\n",
    "               \"Al-Farouq Aminu\": [\"SF\", 16],\n",
    "               \"Frank Kaminsky\": [\"PF\", 19],\n",
    "               \"Tyler Zeller\": [\"C\", 10],\n",
    "               \"Jerian Grant\": [\"PG\", 12],\n",
    "               \"Josh Reaves\": [\"SG\", 1],\n",
    "               \"Trey Burke\": [\"PG\", 7],\n",
    "               \"Jonathan Isaac\": [\"PF\", 19],\n",
    "               \"Cameron Payne\": [\"PG\", 12],\n",
    "               \"Corey Brewer\": [\"SF\", 11],\n",
    "               \"Jaylen Adams\": [\"PG\", 9],\n",
    "               \"Jontay Porter\": [\"PF\", 1],\n",
    "               \"Kyle Guy\": [\"SG\", 2],\n",
    "               \"Grayson Allen\": [\"SG\", 12],\n",
    "               \"Nicolo Melli\": [\"C\", 11.2],\n",
    "               \"JR Smith\": [\"SG\", 15.8],\n",
    "               \"Joakim Noah\": [\"C\", 1.9],\n",
    "               \"Kenrich Williams\": [\"SF\", 8.1],\n",
    "               \"Dion Waiters\": [\"SF\", 8.3],\n",
    "               \"Talen Horton-Tucker\": [\"SG\", 4.2],\n",
    "               \"Nigel Williams-Goss\": [\"PG\", 1.2],\n",
    "               \"Devontae Cacok\": [\"PF\", 0.7],\n",
    "               \"Zylan Cheatham\": [\"PF\", 1.0],\n",
    "               \"Kostas Antetokounmpo\": [\"PF\", 0.4],\n",
    "               \"Jusuf Nurkic\": [\"C\", 24],\n",
    "               \"Donta Hall\": [\"PF\", 9],\n",
    "               \"Michael Beasley\": [\"PF\", 6.5],\n",
    "               \"Lance Thomas\": [\"PF\", 11],\n",
    "               \"Sindarius Thornwell\": [\"SG\", 5],\n",
    "               \"Naz Mitrou-Long\": [\"SG\", 13],\n",
    "               \"Bol Bol\": [\"C\", 14],\n",
    "               \"Keita Bates-Diop\": [\"SF\", 10],\n",
    "               \"Tyler Cook\": [\"PF\", 3],\n",
    "               \"Troy Daniels\": [\"SG\", 8],\n",
    "               \"Kyle Alexander\": [\"PF\", 1],\n",
    "               \"Meyers Leonard\": [\"C\", 15],\n",
    "               \"KZ Okpala\": [\"SF\", 5],\n",
    "               \"Darius Bazley\": [\"PF\", 14],\n",
    "               \"Devon Hall\": [\"SG\", 4],\n",
    "               \"Andre Roberson\": [\"SG\", 5],\n",
    "               \"Marial Shayok\": [\"SG\", 3],\n",
    "               \"Dewan Hernandez\": [\"C\", 4]}\n",
    "\n",
    "#input_data = optimal_lineup_fanduel_games(datetime(2020, 7, 30), preds, fd_csv, [])[1].append(optimal_lineup_fanduel_games(datetime(2020, 7, 31), preds_1, fd_csv_1, [])[1])\n",
    "#input_data = input_data.groupby(\"Position\").mean()\n",
    "input_data.to_csv(\"./AllCSVs/position_mean_data_for_unlisted.csv\")\n",
    "\n",
    "def add_unlisted_players(input_data, player_dict):\n",
    "    position_data = pd.read_csv(\"./AllCSVs/position_mean_data_for_unlisted.csv\")\n",
    "    for player in player_dict.keys():\n",
    "        position = player_dict[player][0]\n",
    "        minutes_guess = player_dict[player][1]\n",
    "        position_guess = position_data.loc[position_data[\"Position\"] == position]\n",
    "        minutes_deflator = minutes_guess/position_guess[\"Minutes\"]\n",
    "        twopt_guess = minutes_deflator*position_guess[\"2PT FG\"]\n",
    "        threept_guess = minutes_deflator*position_guess[\"3PT FG\"]\n",
    "        ft_guess = minutes_deflator*position_guess[\"FTM\"]\n",
    "        rebounds_guess = minutes_deflator*position_guess[\"Rebounds\"]\n",
    "        assists_guess = minutes_deflator*position_guess[\"Assists\"]\n",
    "        blocks_guess = minutes_deflator*position_guess[\"Blocks\"]\n",
    "        steals_guess = minutes_deflator*position_guess[\"Steals\"]\n",
    "        tov_guess = minutes_deflator*position_guess[\"Turnovers\"]\n",
    "        fd_guess = threept_guess * 3 + twopt_guess * 2 + ft_guess + rebounds_guess * 1.2 + assists_guess * 1.5 + blocks_guess * 3 + steals_guess * 3 - tov_guess\n",
    "        dk_guess = threept_guess * 3.5 + twopt_guess * 2 + ft_guess + rebounds_guess * 1.25 + assists_guess * 1.5 + blocks_guess * 2 + steals_guess * 2 - .5 * tov_guess + 1.5 * double_double(threept_guess, twopt_guess, ft_guess, rebounds_guess, assists_guess) + 3 * triple_double(threept_guess, twopt_guess, ft_guess, rebounds_guess, assists_guess)\n",
    "        new_row = [0, player, 0, 0, 0, 0, minutes_guess, twopt_guess, threept_guess, ft_guess, rebounds_guess, assists_guess, blocks_guess, steals_guess, tov_guess, 0, 0, 0, 0, 0, 0, 0, \n",
    "                          0, 0, 0, fd_guess, dk_guess, fd_guess*200, dk_guess*187.5]\n",
    "        input_data = input_data.append(new_row)\n",
    "    return input_data\n",
    "\n",
    "#add_unlisted_players(pd.read_csv(\"./AllCSVs/predictions_for_07_30_2020_unplayed.csv\"), unlisted_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
